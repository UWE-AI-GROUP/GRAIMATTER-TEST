{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f867f23c",
   "metadata": {},
   "source": [
    "# Tensorflow privacy with non TF models\n",
    "\n",
    "This notebook gives an example of using TFPrivacy with non TF models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51ea4487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Scikit-learn classifiers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Tensorflow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "\n",
    "\n",
    "# Imports for MIA\n",
    "from tensorflow_privacy.privacy.privacy_tests.membership_inference_attack import membership_inference_attack as mia\n",
    "from tensorflow_privacy.privacy.privacy_tests.membership_inference_attack.data_structures import AttackInputData\n",
    "from tensorflow_privacy.privacy.privacy_tests.membership_inference_attack.data_structures import SlicingSpec\n",
    "from tensorflow_privacy.privacy.privacy_tests.membership_inference_attack.data_structures import AttackType\n",
    "import tensorflow_privacy.privacy.privacy_tests.membership_inference_attack.plotting as plotting\n",
    "from scipy import special\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53afc583",
   "metadata": {},
   "source": [
    "### Dataset loading\n",
    "\n",
    "Generate classification data using `make_classification`.\n",
    "\n",
    "Split data according to Salem Adversary 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e6d8cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "X, y = make_classification(n_samples=100000, \n",
    "                           n_classes=n_classes, \n",
    "                           random_state=15)\n",
    "\n",
    "\n",
    "# First split is data at TRE and Attacker data from the same distribution\n",
    "X_target, X_shadow, y_target, y_shadow = train_test_split(X, \n",
    "                                                          y, \n",
    "                                                          test_size=0.50, \n",
    "                                                          random_state=15)\n",
    "\n",
    "# Data at TRE is split into train and test data\n",
    "X_target_train, X_target_test, y_target_train, y_target_test = train_test_split(X_target, \n",
    "                                                                                y_target, \n",
    "                                                                                test_size=0.33, \n",
    "                                                                                random_state=15)\n",
    "\n",
    "# X_target will be used to train and test the target model, and as test data for the attack model\n",
    "# X_shadow will be used to train the attack model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a571cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot class encoding for the tensorflow model\n",
    "y_target_train_oh = np.eye(n_classes)[y_target_train]\n",
    "y_target_test_oh = np.eye(n_classes)[y_target_test]\n",
    "y_shadow_oh = np.eye(n_classes)[y_shadow]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60b5dba",
   "metadata": {},
   "source": [
    "### Scikit learn classifiers plus xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7528c12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "    \"XGBoost\"\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", probability=True, C=0.025),\n",
    "    SVC(gamma=2, probability=True, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    XGBClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a4450e",
   "metadata": {},
   "source": [
    "### Small tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f73bd477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow model (MLP)\n",
    "input_data = Input(shape = X_target_train[0].shape)\n",
    "x = Dense(40, activation='relu')(input_data)\n",
    "x = Dense(40, activation='relu')(x)\n",
    "output = Dense(2)(x)\n",
    "\n",
    "tf_clf = Model(input_data, output)\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "tf_clf.compile(optimizer='adam', loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386a3638",
   "metadata": {},
   "source": [
    "### MIA Function definition for sklearn and tensorflow models using TF-Privacy\n",
    "**TODO:** ***Export these functions to separate python files, with docstrings and typing.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d167241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def membership_inference_attack_sklearn(model, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    print('Compute prediction probabilities...')\n",
    "    prob_train = model.predict_proba(X_train)\n",
    "    prob_test = model.predict_proba(X_test)\n",
    "\n",
    "    print('Compute losses...')\n",
    "    cce = tf.keras.backend.categorical_crossentropy\n",
    "    constant = tf.keras.backend.constant\n",
    "\n",
    "    # This might be a bit of a stretch: using categorical crossentropy for all classifiers\n",
    "    loss_train = cce(constant(np.eye(2)[y_train]), constant(prob_train), from_logits=False).numpy()\n",
    "    loss_test = cce(constant(np.eye(2)[y_test]), constant(prob_test), from_logits=False).numpy()\n",
    "\n",
    "    input = AttackInputData(\n",
    "      probs_train = prob_train,\n",
    "      probs_test = prob_test,\n",
    "      loss_train = loss_train,\n",
    "      loss_test = loss_test,\n",
    "      labels_train = y_train,\n",
    "      labels_test = y_test\n",
    "    )\n",
    "\n",
    "    # Run several attacks for different data slices\n",
    "    attacks_result = mia.run_attacks(input,\n",
    "                                     SlicingSpec(\n",
    "                                         entire_dataset = True,\n",
    "                                         by_class = True,\n",
    "                                         by_classification_correctness = True\n",
    "                                     ),\n",
    "                                     attack_types = [\n",
    "                                         AttackType.THRESHOLD_ATTACK,\n",
    "                                         AttackType.LOGISTIC_REGRESSION,\n",
    "                                         AttackType.MULTI_LAYERED_PERCEPTRON,\n",
    "                                         AttackType.RANDOM_FOREST, \n",
    "                                         AttackType.K_NEAREST_NEIGHBORS,\n",
    "                                         #AttackType.THRESHOLD_ENTROPY_ATTACK\n",
    "                                     ])\n",
    "\n",
    "    # Plot the ROC curve of the best classifier\n",
    "    fig = plotting.plot_roc_curve(attacks_result.get_result_with_max_auc().roc_curve)\n",
    "    plt.show()\n",
    "    # Print a user-friendly summary of the attacks\n",
    "    print(attacks_result.summary(by_slices = True))\n",
    "    return attacks_result.get_result_with_max_auc().get_auc(), attacks_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "\n",
    "\n",
    "def membership_inference_attack_tensorflow(model, X_train, X_test, y_train, y_test):\n",
    "    print('Compute logits...')\n",
    "    logits_train = model.predict(X_train, batch_size=32)\n",
    "    logits_test = model.predict(X_test, batch_size=32)\n",
    "\n",
    "    print('Apply softmax to get probabilities from logits...')\n",
    "    prob_train = special.softmax(logits_train, axis=1)\n",
    "    prob_test = special.softmax(logits_test, axis=1)\n",
    "\n",
    "    print('Compute losses...')\n",
    "    cce = tf.keras.backend.categorical_crossentropy\n",
    "    constant = tf.keras.backend.constant\n",
    "\n",
    "    loss_train = cce(constant(y_train), constant(prob_train), from_logits=False).numpy()\n",
    "    loss_test = cce(constant(y_test), constant(prob_test), from_logits=False).numpy()\n",
    "    \n",
    "    labels_train = np.argmax(y_train, axis=1)\n",
    "    labels_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    input = AttackInputData(\n",
    "      logits_train = logits_train,\n",
    "      logits_test = logits_test,\n",
    "      loss_train = loss_train,\n",
    "      loss_test = loss_test,\n",
    "      labels_train = labels_train,\n",
    "      labels_test = labels_test\n",
    "    )\n",
    "\n",
    "    # Run several attacks for different data slices\n",
    "    attacks_result = mia.run_attacks(input,\n",
    "                                     SlicingSpec(\n",
    "                                         entire_dataset = True,\n",
    "                                         by_class = True,\n",
    "                                         by_classification_correctness = True\n",
    "                                     ),\n",
    "                                     attack_types = [\n",
    "                                         AttackType.THRESHOLD_ATTACK,\n",
    "                                         AttackType.LOGISTIC_REGRESSION,\n",
    "                                         AttackType.MULTI_LAYERED_PERCEPTRON,\n",
    "                                         AttackType.RANDOM_FOREST, \n",
    "                                         AttackType.K_NEAREST_NEIGHBORS,\n",
    "                                         AttackType.THRESHOLD_ENTROPY_ATTACK\n",
    "                                     ])\n",
    "\n",
    "    # Plot the ROC curve of the best classifier\n",
    "    fig = plotting.plot_roc_curve(attacks_result.get_result_with_max_auc().roc_curve)\n",
    "    plt.show()\n",
    "    # Print a user-friendly summary of the attacks\n",
    "    print(attacks_result.summary(by_slices = True))\n",
    "    return attacks_result.get_result_with_max_auc().get_auc(), attacks_result.get_result_with_max_attacker_advantage().get_attacker_advantage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cedc3b",
   "metadata": {},
   "source": [
    "### Run experiments on sklearn classifiers and xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d7275df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier Nearest Neighbors...\n",
      "Nearest Neighbors obtained an accuracy of 0.9178181818181819\n",
      "Compute prediction probabilities...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11936/2228330275.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Attack the model using the shadow dataset, and test using the target data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     auc, adv = membership_inference_attack_sklearn(model=clf, \n\u001b[0m\u001b[0;32m     10\u001b[0m                                                    \u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_shadow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                                                    \u001b[0mX_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_target\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11936/1679408545.py\u001b[0m in \u001b[0;36mmembership_inference_attack_sklearn\u001b[1;34m(model, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Compute prediction probabilities...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprob_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mprob_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Compute losses...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\git\\GRAIMatter\\venv\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mby\u001b[0m \u001b[0mlexicographic\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \"\"\"\n\u001b[1;32m--> 256\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\git\\GRAIMatter\\venv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    750\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 752\u001b[1;33m             chunked_results = list(\n\u001b[0m\u001b[0;32m    753\u001b[0m                 pairwise_distances_chunked(\n\u001b[0;32m    754\u001b[0m                     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\git\\GRAIMatter\\venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1715\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1716\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1717\u001b[1;33m         \u001b[0mD_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1718\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[0;32m   1719\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\git\\GRAIMatter\\venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1887\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1889\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1891\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\git\\GRAIMatter\\venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1430\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m     \u001b[1;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\git\\GRAIMatter\\venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    328\u001b[0m             )\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_euclidean_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_norm_squared\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_norm_squared\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\git\\GRAIMatter\\venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_euclidean_distances\u001b[1;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[1;31m# if dtype is already float64, no need to chunk and upcast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m         \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    372\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mYY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\git\\GRAIMatter\\venv\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     if (\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for name, clf in zip(names, classifiers):\n",
    "    print(f'Training classifier {name}...')\n",
    "    # Train and test the target model with X_target and y_target\n",
    "    clf.fit(X_target_train, y_target_train)   \n",
    "    score = clf.score(X_target_test, y_target_test)\n",
    "    print(f'{name} obtained an accuracy of {score}')\n",
    "    \n",
    "    # Attack the model using the shadow dataset, and test using the target data\n",
    "    auc, adv = membership_inference_attack_sklearn(model=clf, \n",
    "                                                   X_train=X_shadow, \n",
    "                                                   X_test=X_target, \n",
    "                                                   y_train=y_shadow, \n",
    "                                                   y_test=y_target)\n",
    "    print(f'Max AUC for MIA is {auc}. Max attacker advantage is {adv}')\n",
    "    print('='*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a51498",
   "metadata": {},
   "source": [
    "### Run experiments on TensorFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5058f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training TensorFlow neural network...')\n",
    "# Train and test the target model with X_target and y_target\n",
    "tf_clf.fit(X_target_train, \n",
    "           y_target_train_oh, \n",
    "           validation_data=(X_target_test, y_target_test_oh),\n",
    "           epochs=10, \n",
    "           batch_size=32\n",
    "          )  \n",
    "# Attack the model using the shadow dataset, and test using the target data\n",
    "auc, adv = membership_inference_attack_tensorflow(model=tf_clf, \n",
    "                                                  X_train=X_shadow, \n",
    "                                                  X_test=X_target, \n",
    "                                                  y_train=y_shadow_oh,\n",
    "                                                  y_test=y_target_oh)\n",
    "print(f'Max AUC for MIA is {auc}. Max attacker advantage is {adv}')\n",
    "print('='*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
