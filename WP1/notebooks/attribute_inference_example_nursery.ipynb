{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running attribute inference attacks on the Nursery data\n",
    "\n",
    "Data fetched from https://www.openml.org/d/26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocess as mp\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger(\"aia_nursery\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "r_state = 1  # random seed\n",
    "attack_threshold = 0  # infer atttributes only if unique highest confidence exceeds this\n",
    "\n",
    "n_cpu = mp.cpu_count()  # number of CPU cores to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility class for storing dataset details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Data:\n",
    "    \"\"\"UCI Nursery dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, seed: int) -> None:\n",
    "        \"\"\"Fetches the UCI Nursery dataset and preprocesses.\"\"\"\n",
    "\n",
    "        self.data = fetch_openml(data_id=26, as_frame=True)\n",
    "        self.names: list[str] = self.data.feature_names\n",
    "        self.X = np.asarray(self.data.data, dtype=str)\n",
    "        self.y = np.asarray(self.data.target, dtype=str)\n",
    "\n",
    "        # target model train / test split\n",
    "        (\n",
    "            self.Xt_member,\n",
    "            self.Xt_nonmember,\n",
    "            self.yt_member,\n",
    "            self.yt_nonmember,\n",
    "        ) = train_test_split(\n",
    "            self.X,\n",
    "            self.y,\n",
    "            test_size=0.5,\n",
    "            stratify=self.y,\n",
    "            shuffle=True,\n",
    "            random_state=seed,\n",
    "        )\n",
    "\n",
    "        # one-hot encoding of features and integer encoding of labels\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.feature_encoder = OneHotEncoder()\n",
    "\n",
    "        self.X_train = self.feature_encoder.fit_transform(self.Xt_member).toarray()\n",
    "        self.y_train = self.label_encoder.fit_transform(self.yt_member)\n",
    "        self.X_test = self.feature_encoder.transform(self.Xt_nonmember).toarray()\n",
    "        self.y_test = self.label_encoder.transform(self.yt_nonmember)\n",
    "        self.n_samples: int = np.shape(self.X_train)[0]\n",
    "        self.n_features: int = np.shape(self.X_train)[1]\n",
    "        self.n_labels: int = len(np.unique(self.y_train))\n",
    "\n",
    "        self.X_all = np.vstack((self.X_train, self.X_test))\n",
    "        self.y_all = np.vstack((self.y_train, self.y_test))\n",
    "\n",
    "        logger.info(f\"X_train shape = {np.shape(self.X_train)}\")\n",
    "        logger.info(f\"y_train shape = {np.shape(self.y_train)}\")\n",
    "        logger.info(f\"X_test shape = {np.shape(self.X_test)}\")\n",
    "        logger.info(f\"y_test shape = {np.shape(self.y_test)}\")\n",
    "        logger.info(f\"n_samples = {self.n_samples}\")\n",
    "        logger.info(f\"n_features = {self.n_features}\")\n",
    "        logger.info(f\"n_labels = {self.n_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility class for storing attacked feature details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttackFeature:\n",
    "    \"\"\"Stores details of the attacked feature.\"\"\"\n",
    "\n",
    "    def __init__(self, ds: Data, index: int, indices: list[int]) -> None:\n",
    "        \"\"\"Initialises the definition of an attack feature.\"\"\"\n",
    "        self.index: int = index  # index of attacked feature\n",
    "        self.name: str = ds.names[index]  # feature name\n",
    "        self.indices: list[int] = indices  # one-hot encoded indices of attacked feature\n",
    "        self.unique = np.unique(ds.X[:, self.index])  # unique attribute values (str)\n",
    "        self.n_unique: int = len(self.unique)  # number of unique attribute values\n",
    "        self.onehot_enc = OneHotEncoder()\n",
    "        self.values = self.onehot_enc.fit_transform(\n",
    "            self.unique.reshape(-1, 1)\n",
    "        ).toarray()  # one-hot encoded unique attribute values\n",
    "        self.X_values = None\n",
    "        self.y_values = None\n",
    "        self.naive: float = 0\n",
    "        logger.debug(f\"Attacked feature unique values: {self.unique}\")\n",
    "\n",
    "    def set_inference_data(self, model, ds: Data) -> None:\n",
    "        \"\"\"Returns a dataset of each sample with every possible missing value for\n",
    "        performing inference. Assumes we know the sample was in the target model\n",
    "        training data and the target model predicted labels are available.\"\"\"\n",
    "        self.X_values = np.zeros(\n",
    "            (ds.n_samples, self.n_unique, ds.n_features), dtype=np.float64\n",
    "        )  # target model training set only\n",
    "        self.y_values = model.predict(ds.X_train)\n",
    "        self.y_strings = ds.label_encoder.inverse_transform(self.y_values)\n",
    "        # for each sample to perform inference on\n",
    "        # add each possible missing feature value\n",
    "        for i, x in enumerate(ds.X_train):\n",
    "            for j, value in enumerate(self.values):\n",
    "                self.X_values[i][j] = np.copy(x)\n",
    "                self.X_values[i][j][self.indices] = value\n",
    "        _, counts = np.unique(ds.Xt_member[:, self.index], return_counts=True)\n",
    "        self.naive = (np.max(counts) / ds.n_samples) * 100\n",
    "        logger.debug(f\"X_values shape = {np.shape(self.X_values)}\")\n",
    "        logger.debug(f\"y_values shape = {np.shape(self.y_values)}\")\n",
    "\n",
    "    def set_inference_data_all(self, model, ds: Data) -> None:\n",
    "        \"\"\"Returns a dataset of each sample with every possible missing value for\n",
    "        performing inference. Uses all train and test samples.\"\"\"\n",
    "        n_samples = len(ds.X_all)\n",
    "        self.X_values = np.zeros(\n",
    "            (n_samples, self.n_unique, ds.n_features), dtype=np.float64\n",
    "        )  # target model training and test set\n",
    "        self.y_values = model.predict(ds.X_all)\n",
    "        self.y_strings = ds.label_encoder.inverse_transform(self.y_values)\n",
    "        # for each sample to perform inference on\n",
    "        # add each possible missing feature value\n",
    "        for i, x in enumerate(ds.X_all):\n",
    "            for j, value in enumerate(self.values):\n",
    "                self.X_values[i][j] = np.copy(x)\n",
    "                self.X_values[i][j][self.indices] = value\n",
    "        _, counts = np.unique(ds.X[:, self.index], return_counts=True)\n",
    "        self.naive = (np.max(counts) / n_samples) * 100\n",
    "        logger.debug(f\"X_values shape = {np.shape(self.X_values)}\")\n",
    "        logger.debug(f\"y_values shape = {np.shape(self.y_values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_max(confidences: list[float], threshold: float) -> bool:\n",
    "    \"\"\"Returns whether there is a unique maximum confidence value above threshold.\"\"\"\n",
    "    if len(confidences) > 0:\n",
    "        max_conf = np.max(confidences)\n",
    "        if max_conf < threshold:\n",
    "            return False\n",
    "        u, c = np.unique(confidences, return_counts=True)\n",
    "        for i in range(len(c)):\n",
    "            if c[i] == 1 and u[i] == max_conf:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aia_nursery:X_train shape = (6480, 27)\n",
      "INFO:aia_nursery:y_train shape = (6480,)\n",
      "INFO:aia_nursery:X_test shape = (6480, 27)\n",
      "INFO:aia_nursery:y_test shape = (6480,)\n",
      "INFO:aia_nursery:n_samples = 6480\n",
      "INFO:aia_nursery:n_features = 27\n",
      "INFO:aia_nursery:n_labels = 5\n"
     ]
    }
   ],
   "source": [
    "dataset = Data(r_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parents</th>\n",
       "      <th>has_nurs</th>\n",
       "      <th>form</th>\n",
       "      <th>children</th>\n",
       "      <th>housing</th>\n",
       "      <th>finance</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parents has_nurs      form children     housing     finance         social  \\\n",
       "0   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "1   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "2   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "3   usual   proper  complete        1  convenient  convenient  slightly_prob   \n",
       "4   usual   proper  complete        1  convenient  convenient  slightly_prob   \n",
       "\n",
       "        health      class  \n",
       "0  recommended  recommend  \n",
       "1     priority   priority  \n",
       "2    not_recom  not_recom  \n",
       "3  recommended  recommend  \n",
       "4     priority   priority  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parents</th>\n",
       "      <th>has_nurs</th>\n",
       "      <th>form</th>\n",
       "      <th>children</th>\n",
       "      <th>housing</th>\n",
       "      <th>finance</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "      <td>12960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4320</td>\n",
       "      <td>2592</td>\n",
       "      <td>3240</td>\n",
       "      <td>3240</td>\n",
       "      <td>4320</td>\n",
       "      <td>6480</td>\n",
       "      <td>4320</td>\n",
       "      <td>4320</td>\n",
       "      <td>4320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       parents has_nurs      form children     housing     finance   social  \\\n",
       "count    12960    12960     12960    12960       12960       12960    12960   \n",
       "unique       3        5         4        4           3           2        3   \n",
       "top      usual   proper  complete        1  convenient  convenient  nonprob   \n",
       "freq      4320     2592      3240     3240        4320        6480     4320   \n",
       "\n",
       "             health      class  \n",
       "count         12960      12960  \n",
       "unique            3          5  \n",
       "top     recommended  not_recom  \n",
       "freq           4320       4320  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model train accuracy: 1.0\n",
      "Base model test accuracy: 0.984104938271605\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(bootstrap=False, random_state=r_state)\n",
    "model.fit(dataset.X_train, dataset.y_train)\n",
    "\n",
    "print(f\"Base model train accuracy: {model.score(dataset.X_train, dataset.y_train)}\")\n",
    "print(f\"Base model test accuracy: {model.score(dataset.X_test, dataset.y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute inference using target model confidence scores and predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, ds: Data, af: AttackFeature, threshold: float) -> str:\n",
    "    \"\"\"\n",
    "    For each possible missing value, compute the confidence scores and\n",
    "    label with the target model; if the label matches the known target model\n",
    "    label for the original sample, and the highest confidence score is unique,\n",
    "    infer that attribute if the confidence score is greater than a threshold.\n",
    "    \"\"\"\n",
    "\n",
    "    # labels and attributes of correct inferences made\n",
    "    correct_label: list[str] = []\n",
    "    correct_attrs: list[str] = []\n",
    "    correct: int = 0  # total number of correct inferences made\n",
    "    total: int = 0  # total number of inferences made\n",
    "\n",
    "    for i, x in enumerate(af.X_values):  # each sample to perform inference on\n",
    "        # get target model confidence scores for the tested sample (batch: all values)\n",
    "        confidences = model.predict_proba(x)\n",
    "        # get known target model predicted label for the original sample\n",
    "        y_label = af.y_values[i]\n",
    "        conf = []  # confidences for each possible value with correct label\n",
    "        attr = []  # features for each possible value with correct label\n",
    "        # for each possible attribute value,\n",
    "        # if the label matches the target model label\n",
    "        # then store the confidence score and the tested feature vector\n",
    "        for j in range(af.n_unique):\n",
    "            y_candidate = np.argmax(confidences[j])\n",
    "            scores = confidences[j][y_candidate]\n",
    "            if y_candidate == y_label:\n",
    "                conf.append(scores)\n",
    "                attr.append(x[j])\n",
    "        # get whether there is a unique maximum confidence score greater than threshold\n",
    "        if unique_max(conf, threshold):\n",
    "            total += 1\n",
    "            # get attributes of the highest confidence matching label\n",
    "            inf = attr[np.argmax(conf)]\n",
    "            inf_str = ds.feature_encoder.inverse_transform(inf.reshape(1, -1))[0]\n",
    "            inf_attr = inf_str[af.index]\n",
    "            # tested sample matches the original input feature\n",
    "            if (inf == ds.X_train[i]).all():\n",
    "                correct_label.append(af.y_strings[i])\n",
    "                correct_attrs.append(inf_attr)\n",
    "                correct += 1\n",
    "\n",
    "    if total > 0:\n",
    "        msg = (\n",
    "            f\"Correctly inferred: {(correct / total) * 100:.2f}% \"\n",
    "            f\"of {(total / len(ds.X_train)) * 100:.2f}% of the data set\\n\"\n",
    "            f\"Baseline: {af.naive:.2f}%\\n\"\n",
    "            f\"{pd.crosstab(correct_label, correct_attrs, rownames=['labels'], colnames=['attrs'])}\"\n",
    "        )\n",
    "    else:\n",
    "        msg = \"Unable to make any inferences\"\n",
    "    return f\"Attacking feature {af.name} with {af.n_unique} unique values:\\n{msg}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of features to attack\n",
    "\n",
    "attack_features = [\n",
    "    AttackFeature(dataset, 0, [0, 1, 2]),  # parents\n",
    "    AttackFeature(dataset, 1, [3, 4, 5, 6, 7]),  # has_nurs\n",
    "    AttackFeature(dataset, 2, [8, 9, 10, 11]),  # form\n",
    "    AttackFeature(dataset, 3, [12, 13, 14, 15]),  # children\n",
    "    AttackFeature(dataset, 4, [16, 17, 18]),  # housing\n",
    "    AttackFeature(dataset, 5, [19, 20]),  # finance\n",
    "    AttackFeature(dataset, 6, [21, 22, 23]),  # social\n",
    "    AttackFeature(dataset, 7, [24, 25, 26]),  # health\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for each attacked feature build a matrix of all possible values\n",
    "# uses training set samples - i.e., assumes attacker knows sample is in dataset\n",
    "for af in attack_features:\n",
    "    af.set_inference_data(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function for collecting parallel processed inferences\n",
    "results: list[str] = []\n",
    "\n",
    "\n",
    "def collect_results(result: str) -> None:\n",
    "    \"\"\"Collects parallel processed inference results.\"\"\"\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacking feature form with 4 unique values:\n",
      "Correctly inferred: 100.00% of 10.71% of the data set\n",
      "Baseline: 25.42%\n",
      "attrs       complete  completed  foster  incomplete\n",
      "labels                                             \n",
      "not_recom         15         12       8           7\n",
      "priority         111         70      80          67\n",
      "recommend          1          0       0           0\n",
      "spec_prior        37         47     106          84\n",
      "very_recom        23         19       1           6\n",
      "\n",
      "Attacking feature children with 4 unique values:\n",
      "Correctly inferred: 100.00% of 12.27% of the data set\n",
      "Baseline: 25.90%\n",
      "attrs         1    2    3  more\n",
      "labels                         \n",
      "not_recom     6   12   16    14\n",
      "priority    179  101   63    59\n",
      "recommend     1    0    0     0\n",
      "spec_prior   26   48  116    90\n",
      "very_recom   41   20    1     2\n",
      "\n",
      "Attacking feature housing with 3 unique values:\n",
      "Correctly inferred: 100.00% of 23.09% of the data set\n",
      "Baseline: 33.47%\n",
      "attrs       convenient  critical  less_conv\n",
      "labels                                     \n",
      "not_recom           45        32         51\n",
      "priority           352       180        191\n",
      "recommend            1         0          0\n",
      "spec_prior          74       289        176\n",
      "very_recom          84         4         17\n",
      "\n",
      "Attacking feature finance with 2 unique values:\n",
      "Correctly inferred: 100.00% of 39.91% of the data set\n",
      "Baseline: 50.12%\n",
      "attrs       convenient  inconv\n",
      "labels                        \n",
      "not_recom          240     208\n",
      "priority           610     494\n",
      "recommend            1       0\n",
      "spec_prior         358     563\n",
      "very_recom          83      29\n",
      "\n",
      "Attacking feature parents with 3 unique values:\n",
      "Correctly inferred: 100.00% of 29.24% of the data set\n",
      "Baseline: 33.55%\n",
      "attrs       great_pret  pretentious  usual\n",
      "labels                                    \n",
      "not_recom           40           42     45\n",
      "priority           140          240    506\n",
      "recommend            0            0      1\n",
      "spec_prior         578          152     55\n",
      "very_recom           0           33     63\n",
      "\n",
      "Attacking feature has_nurs with 5 unique values:\n",
      "Correctly inferred: 100.00% of 17.02% of the data set\n",
      "Baseline: 20.32%\n",
      "attrs       critical  improper  less_proper  proper  very_crit\n",
      "labels                                                        \n",
      "not_recom          1         4            1       1          0\n",
      "priority          51        64          186     190         29\n",
      "recommend          0         0            0       1          0\n",
      "spec_prior       166        55            2       1        299\n",
      "very_recom         0         8           22      22          0\n",
      "\n",
      "Attacking feature social with 3 unique values:\n",
      "Correctly inferred: 100.00% of 21.48% of the data set\n",
      "Baseline: 33.83%\n",
      "attrs       nonprob  problematic  slightly_prob\n",
      "labels                                         \n",
      "not_recom        41           42             39\n",
      "priority        210          204            242\n",
      "recommend         0            0              1\n",
      "spec_prior      101          339             89\n",
      "very_recom       41            0             43\n",
      "\n",
      "Attacking feature health with 3 unique values:\n",
      "Correctly inferred: 100.00% of 72.35% of the data set\n",
      "Baseline: 33.86%\n",
      "attrs       not_recom  priority  recommended\n",
      "labels                                      \n",
      "not_recom        2160         0            0\n",
      "priority            0       511          766\n",
      "recommend           0         0            1\n",
      "spec_prior          0       845          241\n",
      "very_recom          0         0          164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for each feature test each possible value and infer the attribute where possible\n",
    "\n",
    "pool = mp.Pool(processes=n_cpu)\n",
    "for af in attack_features:\n",
    "    pool.apply_async(\n",
    "        infer,\n",
    "        args=(\n",
    "            model,\n",
    "            dataset,\n",
    "            af,\n",
    "            attack_threshold,\n",
    "        ),\n",
    "        callback=collect_results,\n",
    "    )\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "for result in results:\n",
    "    print(f\"{result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membership inference attack\n",
    "#### Construct a dataset with the label of whether or not in the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aia_nursery:mi_train_x shape = (10368, 5)\n",
      "INFO:aia_nursery:mi_train_y shape = (10368,)\n",
      "INFO:aia_nursery:mi_test_x shape = (2592, 5)\n",
      "INFO:aia_nursery:mi_test_y shape = (2592,)\n"
     ]
    }
   ],
   "source": [
    "miX = model.predict_proba(dataset.X_all)\n",
    "\n",
    "miY = np.vstack(\n",
    "    (np.ones((len(dataset.X_train), 1), int), np.zeros((len(dataset.X_test), 1), int))\n",
    ").flatten()\n",
    "\n",
    "mi_train_x, mi_test_x, mi_train_y, mi_test_y = train_test_split(\n",
    "    miX, miY, test_size=0.2, stratify=miY\n",
    ")\n",
    "\n",
    "logger.info(f\"mi_train_x shape = {np.shape(mi_train_x)}\")\n",
    "logger.info(f\"mi_train_y shape = {np.shape(mi_train_y)}\")\n",
    "logger.info(f\"mi_test_x shape = {np.shape(mi_test_x)}\")\n",
    "logger.info(f\"mi_test_y shape = {np.shape(mi_test_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train membership inference attack model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membership AUC = 0.9264927221460143\n"
     ]
    }
   ],
   "source": [
    "mi_attack_model = RandomForestClassifier()\n",
    "mi_attack_model.fit(mi_train_x, mi_train_y)\n",
    "\n",
    "pred_probs = mi_attack_model.predict_proba(mi_test_x)\n",
    "mi_auc = roc_auc_score(mi_test_y, pred_probs[:, 1])\n",
    "print(f\"Membership AUC = {mi_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute inference and membership inference\n",
    "Same attack as above, however training set membership is not assumed, and a membership inference model is used first to classify member/non-member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, mia_model, ds: Data, af: AttackFeature, threshold: float) -> str:\n",
    "    \"\"\"Infers the missing feature values.\"\"\"\n",
    "\n",
    "    # labels and attributes of correct inferences made\n",
    "    correct_label: list[str] = []\n",
    "    correct_attrs: list[str] = []\n",
    "    correct: int = 0  # total number of correct inferences made\n",
    "    total: int = 0  # total number of inferences made\n",
    "\n",
    "    for i, x in enumerate(af.X_values):  # each sample to perform inference on\n",
    "        # get target model confidence scores for the tested sample\n",
    "        confidence = model.predict_proba(x)\n",
    "        # get membership inference model confidence scores for the tested sample\n",
    "        mi_confidence = mia_model.predict_proba(confidence)\n",
    "        # get known target model predicted label for the original sample\n",
    "        label = af.y_values[i]\n",
    "        conf = []  # confidences for each possible value with correct label\n",
    "        attr = []  # features for each possible value with correct label\n",
    "        # for each possible attribute value,\n",
    "        # if mia predicts memberset and label matches target model\n",
    "        # then store the confidence score and the tested feature vector\n",
    "        for j in range(af.n_unique):\n",
    "            mia_label = np.argmax(mi_confidence[j])\n",
    "            this_label = np.argmax(confidence[j])\n",
    "            if mia_label == 1 and this_label == label:\n",
    "                scores = confidence[j][this_label]\n",
    "                conf.append(scores)\n",
    "                attr.append(x[j])\n",
    "        # get whether there is a unique maximum confidence score greater than threshold\n",
    "        if unique_max(conf, threshold):\n",
    "            total += 1\n",
    "            # get attributes of the highest confidence matching label\n",
    "            inf = attr[np.argmax(conf)]\n",
    "            inf_str = ds.feature_encoder.inverse_transform(inf.reshape(1, -1))[0]\n",
    "            inf_attr = inf_str[af.index]\n",
    "            # tested sample matches the original input feature\n",
    "            if (inf == ds.X_all[i]).all():\n",
    "                correct_label.append(af.y_strings[i])\n",
    "                correct_attrs.append(inf_attr)\n",
    "                correct += 1\n",
    "\n",
    "    if total > 0:\n",
    "        msg = (\n",
    "            f\"Correctly inferred: {(correct / total) * 100:.2f}% \"\n",
    "            f\"of {(total / len(ds.X_all)) * 100:.2f}% of the data set\\n\"\n",
    "            f\"Baseline: {af.naive:.2f}%\\n\"\n",
    "            f\"{pd.crosstab(correct_label, correct_attrs, rownames=['labels'], colnames=['attrs'])}\"\n",
    "        )\n",
    "    else:\n",
    "        msg = \"Unable to make any inferences\"\n",
    "    return f\"Attacking feature {af.name} with {af.n_unique} unique values:\\n{msg}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses training and testing set - i.e., does not assume dataset membership\n",
    "for af in attack_features:\n",
    "    af.set_inference_data_all(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacking feature children with 4 unique values:\n",
      "Correctly inferred: 34.18% of 18.49% of the data set\n",
      "Baseline: 25.00%\n",
      "attrs         1    2    3  more\n",
      "labels                         \n",
      "not_recom     8   14   21    17\n",
      "priority    180  103   64    61\n",
      "recommend     1    0    0     0\n",
      "spec_prior   26   49  118    93\n",
      "very_recom   41   20    1     2\n",
      "\n",
      "Attacking feature parents with 3 unique values:\n",
      "Correctly inferred: 51.85% of 30.43% of the data set\n",
      "Baseline: 33.33%\n",
      "attrs       great_pret  pretentious  usual\n",
      "labels                                    \n",
      "not_recom           56           60     73\n",
      "priority           143          247    542\n",
      "recommend            0            0      1\n",
      "spec_prior         612          159     56\n",
      "very_recom           0           33     63\n",
      "\n",
      "Attacking feature finance with 2 unique values:\n",
      "Correctly inferred: 54.47% of 40.29% of the data set\n",
      "Baseline: 50.00%\n",
      "attrs       convenient  inconv\n",
      "labels                        \n",
      "not_recom          320     278\n",
      "priority           629     509\n",
      "recommend            1       0\n",
      "spec_prior         390     605\n",
      "very_recom          83      29\n",
      "\n",
      "Attacking feature housing with 3 unique values:\n",
      "Correctly inferred: 43.62% of 28.41% of the data set\n",
      "Baseline: 33.33%\n",
      "attrs       convenient  critical  less_conv\n",
      "labels                                     \n",
      "not_recom           73        45         64\n",
      "priority           363       187        198\n",
      "recommend            1         0          0\n",
      "spec_prior          76       308        186\n",
      "very_recom          84         4         17\n",
      "\n",
      "Attacking feature has_nurs with 5 unique values:\n",
      "Correctly inferred: 42.11% of 21.37% of the data set\n",
      "Baseline: 20.00%\n",
      "attrs       critical  improper  less_proper  proper  very_crit\n",
      "labels                                                        \n",
      "not_recom          2         5            1       1          0\n",
      "priority          51        66          194     200         29\n",
      "recommend          0         0            0       1          0\n",
      "spec_prior       177        55            2       1        329\n",
      "very_recom         0         8           22      22          0\n",
      "\n",
      "Attacking feature social with 3 unique values:\n",
      "Correctly inferred: 41.96% of 27.53% of the data set\n",
      "Baseline: 33.33%\n",
      "attrs       nonprob  problematic  slightly_prob\n",
      "labels                                         \n",
      "not_recom        60           60             55\n",
      "priority        219          216            247\n",
      "recommend         0            0              1\n",
      "spec_prior      104          360             91\n",
      "very_recom       41            0             43\n",
      "\n",
      "Attacking feature health with 3 unique values:\n",
      "Correctly inferred: 80.43% of 58.58% of the data set\n",
      "Baseline: 33.33%\n",
      "attrs       not_recom  priority  recommended\n",
      "labels                                      \n",
      "not_recom        3354         0            0\n",
      "priority            0       572          790\n",
      "recommend           0         0            1\n",
      "spec_prior          0       969          256\n",
      "very_recom          0         0          164\n",
      "\n",
      "Attacking feature form with 4 unique values:\n",
      "Correctly inferred: 31.63% of 17.79% of the data set\n",
      "Baseline: 25.00%\n",
      "attrs       complete  completed  foster  incomplete\n",
      "labels                                             \n",
      "not_recom         17         19      11           9\n",
      "priority         113         71      84          68\n",
      "recommend          1          0       0           0\n",
      "spec_prior        39         50     110          88\n",
      "very_recom        23         19       1           6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for each feature test each possible value and infer the attribute where possible\n",
    "\n",
    "results = []\n",
    "\n",
    "pool = mp.Pool(processes=n_cpu)\n",
    "for af in attack_features:\n",
    "    pool.apply_async(\n",
    "        infer,\n",
    "        args=(\n",
    "            model,\n",
    "            mi_attack_model,\n",
    "            dataset,\n",
    "            af,\n",
    "            attack_threshold,\n",
    "        ),\n",
    "        callback=collect_results,\n",
    "    )\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "for result in results:\n",
    "    print(f\"{result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute inference using a membership inference attack model\n",
    "The idea is to find the target feature value that causes the membership inference attack to classify the sample as a member with the highest confidence. Here the attacker is not sure if the sample is in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_mia(model, mia_model, ds: Data, af: AttackFeature, threshold: float) -> str:\n",
    "    \"\"\"Infers the missing feature values with a membership inference attack model.\"\"\"\n",
    "\n",
    "    # labels and attributes of correct inferences made\n",
    "    correct_label: list[str] = []\n",
    "    correct_attrs: list[str] = []\n",
    "    correct: int = 0  # total number of correct inferences made\n",
    "    total: int = 0  # total number of inferences made\n",
    "\n",
    "    for i, x in enumerate(af.X_values):  # each sample to perform inference on\n",
    "        # get target model confidence scores for the tested sample\n",
    "        confidence = model.predict_proba(x)\n",
    "        # get membership inference model confidence scores for the tested sample\n",
    "        mi_confidence = mia_model.predict_proba(confidence)\n",
    "        conf = []  # confidences for each possible value with member label\n",
    "        attr = []  # features for each possible value with member label\n",
    "        # for each possible attribute value,\n",
    "        # if the membership inference model predicts training set membership\n",
    "        # then store the confidence score and the tested feature vector\n",
    "        for j in range(af.n_unique):\n",
    "            this_label = np.argmax(mi_confidence[j])\n",
    "            scores = mi_confidence[j][this_label]\n",
    "            if this_label == 1:\n",
    "                conf.append(scores)\n",
    "                attr.append(x[j])\n",
    "        # get whether there is a unique maximum confidence score greater than threshold\n",
    "        if unique_max(conf, threshold):\n",
    "            total += 1\n",
    "            # get attributes of the highest confidence matching label\n",
    "            inf = attr[np.argmax(conf)]\n",
    "            inf_str = ds.feature_encoder.inverse_transform(inf.reshape(1, -1))[0]\n",
    "            inf_attr = inf_str[af.index]\n",
    "            # tested sample matches the original input feature\n",
    "            if (inf == ds.X_all[i]).all():\n",
    "                correct_label.append(af.y_strings[i])\n",
    "                correct_attrs.append(inf_attr)\n",
    "                correct += 1\n",
    "\n",
    "    if total > 0:\n",
    "        msg = (\n",
    "            f\"Correctly inferred: {(correct / total) * 100:.2f}% \"\n",
    "            f\"of {(total / len(ds.X_all)) * 100:.2f}% of the data set\\n\"\n",
    "            f\"Baseline: {af.naive:.2f}%\\n\"\n",
    "            f\"{pd.crosstab(correct_label, correct_attrs, rownames=['labels'], colnames=['attrs'])}\"\n",
    "        )\n",
    "    else:\n",
    "        msg = \"Unable to make any inferences\"\n",
    "    return f\"Attacking feature {af.name} with {af.n_unique} unique values:\\n{msg}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacking feature form with 4 unique values:\n",
      "Correctly inferred: 25.00% of 18.86% of the data set\n",
      "Baseline: 25.00%\n",
      "attrs       complete  completed  foster  incomplete\n",
      "labels                                             \n",
      "not_recom         17         19      11           9\n",
      "priority         113         70      62          63\n",
      "spec_prior        39         41      61          57\n",
      "very_recom        23         19       1           6\n",
      "\n",
      "Attacking feature finance with 2 unique values:\n",
      "Correctly inferred: 50.00% of 42.13% of the data set\n",
      "Baseline: 50.00%\n",
      "attrs       convenient  inconv\n",
      "labels                        \n",
      "not_recom          320     278\n",
      "priority           629     481\n",
      "recommend            1       0\n",
      "spec_prior         390     519\n",
      "very_recom          83      29\n",
      "\n",
      "Attacking feature has_nurs with 5 unique values:\n",
      "Correctly inferred: 20.00% of 24.31% of the data set\n",
      "Baseline: 20.00%\n",
      "attrs       critical  improper  less_proper  proper  very_crit\n",
      "labels                                                        \n",
      "not_recom          2         5            1       1          0\n",
      "priority          23        61          194     200          3\n",
      "spec_prior        29        12            2       1         44\n",
      "very_recom         0         8           22      22          0\n",
      "\n",
      "Attacking feature health with 3 unique values:\n",
      "Correctly inferred: 33.33% of 73.31% of the data set\n",
      "Baseline: 33.33%\n",
      "attrs       not_recom  priority  recommended\n",
      "labels                                      \n",
      "not_recom         724         0            0\n",
      "priority            0       495          790\n",
      "spec_prior          0       738          256\n",
      "very_recom          0         0          164\n",
      "\n",
      "Attacking feature social with 3 unique values:\n",
      "Correctly inferred: 33.33% of 29.42% of the data set\n",
      "Baseline: 33.33%\n",
      "attrs       nonprob  problematic  slightly_prob\n",
      "labels                                         \n",
      "not_recom        60           60             55\n",
      "priority        219          147            247\n",
      "recommend         0            0              1\n",
      "spec_prior      104          203             91\n",
      "very_recom       41            0             43\n",
      "\n",
      "Attacking feature parents with 3 unique values:\n",
      "Correctly inferred: 33.33% of 36.50% of the data set\n",
      "Baseline: 33.33%\n",
      "attrs       great_pret  pretentious  usual\n",
      "labels                                    \n",
      "not_recom           56           60     73\n",
      "priority            94          239    542\n",
      "recommend            0            0      1\n",
      "spec_prior         254          106     56\n",
      "very_recom           0           33     63\n",
      "\n",
      "Attacking feature children with 4 unique values:\n",
      "Correctly inferred: 25.00% of 21.20% of the data set\n",
      "Baseline: 25.00%\n",
      "attrs         1   2   3  more\n",
      "labels                       \n",
      "not_recom     8  14  21    17\n",
      "priority    180  97  53    47\n",
      "spec_prior   26  34  65    61\n",
      "very_recom   41  20   1     2\n",
      "\n",
      "Attacking feature housing with 3 unique values:\n",
      "Correctly inferred: 33.33% of 31.81% of the data set\n",
      "Baseline: 33.33%\n",
      "attrs       convenient  critical  less_conv\n",
      "labels                                     \n",
      "not_recom           73        45         64\n",
      "priority           363       134        188\n",
      "spec_prior          76       176        150\n",
      "very_recom          84         4         17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# uses training and testing set - i.e., does not assume dataset membership\n",
    "\n",
    "results = []\n",
    "\n",
    "pool = mp.Pool(processes=n_cpu)\n",
    "for af in attack_features:\n",
    "    pool.apply_async(\n",
    "        infer_mia,\n",
    "        args=(\n",
    "            model,\n",
    "            mi_attack_model,\n",
    "            dataset,\n",
    "            af,\n",
    "            attack_threshold,\n",
    "        ),\n",
    "        callback=collect_results,\n",
    "    )\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "for result in results:\n",
    "    print(f\"{result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute inference mapping n-1 features and labels to the missing feature\n",
    "This black-box attack trains an additional classifier (the attack model) to predict the attacked feature's value from the remaining n-1 features as well as the original (target) model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_bb_data(ds: Data, af: AttackFeature):\n",
    "    \"\"\"Returns data for fitting a black-box model on n-1 features plus predictions.\"\"\"\n",
    "    # get target vector of attacked feature\n",
    "    ya = ds.Xt_member[:, af.index]\n",
    "    # label encode attacked feature - for sklearn classifiers\n",
    "    attacked_feature_encoder = LabelEncoder()\n",
    "    ya = attacked_feature_encoder.fit_transform(ya)\n",
    "    # combine predictions with n-1 features for attack model input\n",
    "    Xa = np.copy(ds.X_train)\n",
    "    predictions = model.predict_proba(Xa)  # get target model's confidences\n",
    "    Xa = np.delete(Xa, af.indices, axis=1)  # drop attacked feature\n",
    "    Xa = np.concatenate((Xa, predictions), axis=1)  # combine label predictions\n",
    "    # attack model train / test split\n",
    "    Xa_train, Xa_test, ya_train, ya_test = train_test_split(\n",
    "        Xa, ya, test_size=0.2, shuffle=False, random_state=r_state\n",
    "    )\n",
    "    return Xa_train, ya_train, Xa_test, ya_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_models = []\n",
    "\n",
    "attack_models.append(\n",
    "    [\n",
    "        \"MLPClassifier\",\n",
    "        MLPClassifier(\n",
    "            hidden_layer_sizes=(100,),\n",
    "            activation=\"relu\",\n",
    "            solver=\"adam\",\n",
    "            alpha=0.0001,\n",
    "            batch_size=\"auto\",\n",
    "            learning_rate=\"constant\",\n",
    "            learning_rate_init=0.001,\n",
    "            power_t=0.5,\n",
    "            max_iter=2000,\n",
    "            shuffle=True,\n",
    "            random_state=r_state,\n",
    "            tol=0.0001,\n",
    "            verbose=False,\n",
    "            warm_start=False,\n",
    "            momentum=0.9,\n",
    "            nesterovs_momentum=True,\n",
    "            early_stopping=False,\n",
    "            validation_fraction=0.1,\n",
    "            beta_1=0.9,\n",
    "            beta_2=0.999,\n",
    "            epsilon=1e-08,\n",
    "            n_iter_no_change=10,\n",
    "            max_fun=15000,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "attack_models.append([\"RandomForrestClassifier\", RandomForestClassifier()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacking feature: parents\n",
      "MLPClassifier attack model\n",
      "(Train, Test) accuracy: (0.61285, 0.33565)\n",
      "RandomForrestClassifier attack model\n",
      "(Train, Test) accuracy: (0.72434, 0.25386)\n",
      "\n",
      "Attacking feature: has_nurs\n",
      "MLPClassifier attack model\n",
      "(Train, Test) accuracy: (0.44753, 0.17978)\n",
      "RandomForrestClassifier attack model\n",
      "(Train, Test) accuracy: (0.59008, 0.10880)\n",
      "\n",
      "Attacking feature: form\n",
      "MLPClassifier attack model\n",
      "(Train, Test) accuracy: (0.43133, 0.16590)\n",
      "RandomForrestClassifier attack model\n",
      "(Train, Test) accuracy: (0.56520, 0.06944)\n",
      "\n",
      "Attacking feature: children\n",
      "MLPClassifier attack model\n",
      "(Train, Test) accuracy: (0.43576, 0.18133)\n",
      "RandomForrestClassifier attack model\n",
      "(Train, Test) accuracy: (0.57330, 0.08719)\n",
      "\n",
      "Attacking feature: housing\n",
      "MLPClassifier attack model\n",
      "(Train, Test) accuracy: (0.55652, 0.27778)\n",
      "RandomForrestClassifier attack model\n",
      "(Train, Test) accuracy: (0.69155, 0.18056)\n",
      "\n",
      "Attacking feature: finance\n",
      "MLPClassifier attack model\n",
      "(Train, Test) accuracy: (0.72531, 0.40741)\n",
      "RandomForrestClassifier attack model\n",
      "(Train, Test) accuracy: (0.81462, 0.35108)\n",
      "\n",
      "Attacking feature: social\n",
      "MLPClassifier attack model\n",
      "(Train, Test) accuracy: (0.55363, 0.25000)\n",
      "RandomForrestClassifier attack model\n",
      "(Train, Test) accuracy: (0.68306, 0.17824)\n",
      "\n",
      "Attacking feature: health\n",
      "MLPClassifier attack model\n",
      "(Train, Test) accuracy: (0.84452, 0.70756)\n",
      "RandomForrestClassifier attack model\n",
      "(Train, Test) accuracy: (0.90548, 0.65586)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for af in attack_features:\n",
    "    print(f\"Attacking feature: {af.name}\")\n",
    "    Xa_train, ya_train, Xa_test, ya_test = get_bb_data(dataset, af)\n",
    "    for name, attack_model in attack_models:\n",
    "        print(f\"{name} attack model\")\n",
    "        attack_model.fit(Xa_train, ya_train)\n",
    "        print(\n",
    "            \"(Train, Test) accuracy: \"\n",
    "            f\"({attack_model.score(Xa_train, ya_train):.5f}, \"\n",
    "            f\"{attack_model.score(Xa_test, ya_test):.5f})\"\n",
    "        )\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues\n",
    "\n",
    "* Does it matter if you can only predict missing values for **x**% of the people, as long as you can do it accurately for that **x**%?\n",
    "* Following on, would there be a minimum value of vulnerable percentage **x** (or number of people) below which you didn't care?\n",
    "* Should TREs have to flag which attributes they care about being vulnerable?\n",
    "* Does using safe params reduce the risk of attribute vulnerability?\n",
    "* Is it disclosive if you can say for attribute **A**, the value is definitely not **a**?\n",
    "* Is vulnerability of an attribute linked to feature importance as predicted by the classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
