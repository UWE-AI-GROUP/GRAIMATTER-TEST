{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(\"\")))\n",
    "sys.path.append(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Scikit-learn utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification, make_moons\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "# Tensorflow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "\n",
    "# Classifiers for attack models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import t=privachy version \n",
    "import tensorflow_privacy\n",
    "\n",
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the datasets\n",
    "1. We draw data points from a distribution.\n",
    "2. We split these data points into the target dataset and a shadow dataset drawn from the same distribution.\n",
    "3. We also draw a dataset from a different distribution.\n",
    "\n",
    "**NOTE**. ***I make datasets with few samples but with many features to force the target model to overfit.***\n",
    "\n",
    "\n",
    "***NOTE JIM: had to make batch_size 25 so DP optimizer would run with same hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "\n",
    "# (X,y): Original distribution\n",
    "X, y = make_classification(n_samples=1000,\n",
    "                           n_classes=n_classes, \n",
    "                           n_features=300,\n",
    "                           n_informative=300,\n",
    "                           n_redundant=0,\n",
    "                           n_repeated=0,\n",
    "                           random_state=15\n",
    "                          )\n",
    "# One-hot encoding of the label\n",
    "y = np.eye(n_classes)[y]\n",
    "\n",
    "# (Xt, yt) is the target dataset, owned by the TRE and drawn from the (X,y) distribution\n",
    "# (Xs, ys) is a shadow dataset drawn from the (X,y) distribution\n",
    "Xt, Xs, yt, ys = train_test_split(X, y, test_size=0.50, random_state=15)\n",
    "\n",
    "# (Xd, yd) is a shadow dataset, drawn from a different distribution (different seed)\n",
    "Xd, yd = make_classification(n_samples=1000,\n",
    "                           n_classes=n_classes, \n",
    "                           n_features=300,\n",
    "                           n_informative=300,\n",
    "                           n_redundant=0,\n",
    "                           n_repeated=0,\n",
    "                           random_state=42\n",
    "                          )\n",
    "yd = np.eye(n_classes)[yd]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train (member) and test (non-member) datasets\n",
    "# Set shuffle to False so that Xt_membership is consistent with Xt, otherwise\n",
    "# we need to stack Xt_member and Xt_nonmember again to get a consistent Xt.\n",
    "Xt_member, Xt_nonmember, yt_member, yt_nonmember = train_test_split(Xt, yt, test_size=0.5, shuffle=False)\n",
    "\n",
    "# Set membership status for future tests\n",
    "Xt_membership = np.vstack(\n",
    "    (\n",
    "        np.ones((Xt_member.shape[0], 1), np.uint8),\n",
    "        np.zeros((Xt_nonmember.shape[0], 1), np.uint8)\n",
    "    )\n",
    ").flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the target model architecture\n",
    "\n",
    "*Again, I'm using a rather big model (for the classification task) to favour overfitting.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target model\n",
    "# Tensorflow model (MLP) (making it big to make it overfit)\n",
    "input_data = Input(shape = Xt_member[0].shape)\n",
    "x = Dense(128, activation='relu')(input_data)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output = Dense(2, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now try the SafeKerasModel version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import safemodel\n",
    "from safemodel.classifiers.safekeras import Safe_KerasModel\n",
    "\n",
    "\n",
    "\n",
    "importlib.reload(safemodel.safemodel)\n",
    "importlib.reload(safemodel.classifiers.safekeras)\n",
    "from safemodel.classifiers.safekeras import Safe_KerasModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args is a <class 'tuple'> = ()  kwargs is a <class 'dict'>= {'inputs': <KerasTensor: shape=(None, 300) dtype=float32 (created by layer 'input_2')>, 'outputs': <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'dense_7')>}\n",
      "WARNING: model parameters may present a disclosure risk:\n",
      "- parameter optimizer = None identified as different type to recommendation of tensorflow_privacy.privacy.optimizers.dp_optimizer_keras.make_keras_optimizer_class.<locals>.DPOptimizerClass.Nothing currently implemented to change type of parameter optimizer from NoneType to tensorflow_privacy.privacy.optimizers.dp_optimizer_keras.make_keras_optimizer_class.<locals>.DPOptimizerClass.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer=None\n",
    "safeModel = Safe_KerasModel(inputs= input_data, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#safeModel.__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "safeModel.compile()#optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimiser is type <class 'tensorflow_privacy.privacy.optimizers.dp_optimizer_keras.make_keras_optimizer_class.<locals>.DPOptimizerClass'>\n",
      " It is False that the moddel will be DP because optimiser has been changed but fit() has not been rerun.\n"
     ]
    }
   ],
   "source": [
    "theType= type(safeModel.optimizer)\n",
    "print(f'optimiser is type {theType}')\n",
    "\n",
    "dpused,reason = safeModel.check_DP_used(safeModel.optimizer)\n",
    "print(f' It is {dpused} that the moddel will be DP because {reason}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/Users/j4-smith/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n\n    TypeError: tf__call() got an unexpected keyword argument 'training'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4m/prf7hx2x71dd2kz4x0g_v6hc000369/T/ipykernel_55772/3618035315.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m safeModel.fit(Xt_member, \n\u001b[0m\u001b[1;32m      5\u001b[0m               \u001b[0myt_member\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt_nonmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt_nonmember\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/Users/j4-smith/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n\n    TypeError: tf__call() got an unexpected keyword argument 'training'\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 25\n",
    "\n",
    "safeModel.fit(Xt_member, \n",
    "              yt_member, \n",
    "              validation_data=(Xt_nonmember, yt_nonmember),\n",
    "              epochs=epochs, \n",
    "              batch_size=batch_size\n",
    ")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimiser is type <class 'tensorflow_privacy.privacy.optimizers.dp_optimizer_keras.make_keras_optimizer_class.<locals>.DPOptimizerClass'>\n",
      " It is False that the moddel will b e DP becauyse optimiser has been changed but fit() has not been rerun.\n"
     ]
    }
   ],
   "source": [
    "theType= type(safeModel.optimizer)\n",
    "print(f'optimiser is type {theType}')\n",
    "\n",
    "dpused,reason = safeModel.check_DP_used(safeModel.optimizer)\n",
    "print(f' It is {dpused} that the moddel will be DP because {reason}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safeModel.save('safekeras.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safeModel.preliminary_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safeModel.request_release('safekeras.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit using recommended params\n",
    "print(\"***Test 1: researcher doesn't change recommended params\")\n",
    "safeKerasModel1 = Safe_KerasModel(input_data, output)\n",
    "safeKerasModel1.compile()\n",
    "safeKerasModel1.fit(Xt_member, \n",
    "                    yt_member, \n",
    "                    validation_data=(Xt_nonmember, yt_nonmember),\n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size)\n",
    "safeKerasModel1.save(name=\"safe1.pkl\")\n",
    "safeKerasModel1.preliminary_check()\n",
    "safeKerasModel1.request_release(filename=\"safe1.pkl\")\n",
    "\n",
    "\n",
    "# change model params to recommended values\n",
    "print(\"\\n***Test 2: researcher changes params safely\")\n",
    "safeKerasModel2 = Safe_KerasModel(input_data, output)\n",
    "safeKerasModel2.compile()\n",
    "safeKerasModel2.optimizer=\"DPAdam\"\n",
    "safeKerasModel2.fit(Xt_member, \n",
    "                    yt_member, \n",
    "                    validation_data=(Xt_nonmember, yt_nonmember),\n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size)\n",
    "safeKerasModel2.save(name=\"safe2.pkl\")\n",
    "safeKerasModel2.preliminary_check()\n",
    "safeKerasModel2.request_release(filename=\"safe2.pkl\")\n",
    "\n",
    "# change one model params in an unsafe way\n",
    "print(\"\\n***Test 3: researcher changes string params unsafely\")\n",
    "safeKerasModel3 = Safe_KerasModel(input_data, output)\n",
    "safeKerasModel3.compile()\n",
    "safeKerasModel3.optimizer=\"Adam\"\n",
    "safeKerasModel3.fit(Xt_member, \n",
    "                    yt_member, \n",
    "                    validation_data=(Xt_nonmember, yt_nonmember),\n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size)\n",
    "safeKerasModel3.save(name=\"unsafe3.pkl\")\n",
    "safeKerasModel3.preliminary_check()\n",
    "safeKerasModel3.request_release(filename=\"unsafe3.pkl\")\n",
    "\n",
    "# change another model params in an  unsafe way\n",
    "\n",
    "\n",
    "# change another model params in an  unsafe way\n",
    "print(\"\\n***Test 5: researcher changes string and numeric params unsafely\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change another model params in an  unsafe way but tells preliminary_check() not to overwrite params\n",
    "print(\"\\n***Test 6: researcher changes string and numeric params unsafely\")\n",
    "safeKerasModel6 = Safe_KerasModel(input_data, output)\n",
    "safeKerasModel6.compile()\n",
    "safeKerasModel6.optimizer=\"Adam\"\n",
    "safeKerasModel6.fit(Xt_member, \n",
    "                    yt_member, \n",
    "                    validation_data=(Xt_nonmember, yt_nonmember),\n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size)\n",
    "safeKerasModel6.save(name=\"unsafe6.pkl\")\n",
    "safeKerasModel6.preliminary_check(apply_constraints=False)\n",
    "safeKerasModel6.request_release(filename=\"unsafe6.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
