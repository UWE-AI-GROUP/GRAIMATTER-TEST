{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0102479a-ecb2-4ffb-8aaa-6d21c90a06f0",
   "metadata": {},
   "source": [
    "## Test ($\\epsilon$,$\\delta$)-differentially private synthetic data generation on simple dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7e01a9-3da6-4c75-8596-8da820265b68",
   "metadata": {},
   "source": [
    "In this notebook, we investigate the effect of enforcing differential privacy on usefulness of synthetic data. We firstly generate a simple dataset consisting of four independently unit-Gaussian distributed covariates $X$, and a Bernoulli-distributed outcome $Y$ with $E(Y)=logistic(\\beta X)$\n",
    "\n",
    "We make use of a public github library for [differentially private synthetic data generation](https://github.com/BorealisAI/private-data-generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d31510-c961-43bd-b180-de3e8d3953e3",
   "metadata": {},
   "source": [
    "Control parameters are as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c393d9d3-ab38-4a04-899f-d96fb60bcc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "## File paths --------------------------------------------##\n",
    "############################################################\n",
    "\n",
    "# File paths for original and synthesised data sets\n",
    "orig_path='/home/ec2-user/studies/GRAIMatter/data/Synthetic_generation/Original/'\n",
    "synth_path='/home/ec2-user/studies/GRAIMatter/data/Synthetic_generation/Synthetic/'\n",
    "\n",
    "# File path containing evaluate.py and PDG repository\n",
    "pdg_path='/home/ec2-user/GRAIMatter/WP1/models/Synthetic_data/'\n",
    "\n",
    "# File path to which outputs will be saved. Should contain directories called Figures, Tables\n",
    "output_path='/home/ec2-user/GRAIMatter/WP1/reports/synthetic_data/'\n",
    "\n",
    "\n",
    "############################################################\n",
    "## Synth. generation methods and DP levels ---------------##\n",
    "############################################################\n",
    "\n",
    "# This parameter can be 'dp-wgan' or 'pate-gan' (GAN-based) or 'ron-gauss' (Gaussian projection)\n",
    "#  Other options may be added. The parameter synth_extra governs extra parameters to be passed - \n",
    "#  see evaluate.py for details\n",
    "synth_method='dp-wgan'; synth_extra='--sigma=0.8'\n",
    "#synth_method='ron-gauss'; synth_extra='';\n",
    "\n",
    "# We will consider epsilon-DP for these epsilon levels\n",
    "dp_levels=[1,2,4,8]\n",
    "\n",
    "# This parameter controls whether output from the system call to evaluate.py is shown in the notebook\n",
    "show_output=True\n",
    "\n",
    "\n",
    "\n",
    "############################################################\n",
    "## Data parameters ---------------------------------------##\n",
    "############################################################\n",
    "\n",
    "# Random seed\n",
    "random_seed=38273\n",
    "\n",
    "# Simulate this many points\n",
    "nx=10000\n",
    "\n",
    "# Number of covariates\n",
    "p=4\n",
    "\n",
    "# Parameters of Gaussian distribution for IID covariates\n",
    "mu=0\n",
    "sigma=1\n",
    "\n",
    "# Coefficients of logistic model for Y\n",
    "beta0=[0.5,1,-1,-0.5]\n",
    "beta=tuple([10*x for x in beta0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f166a108-1645-4354-8169-3453f1abc38c",
   "metadata": {},
   "source": [
    "Preliminary set-up as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bd367ac-a0e4-4906-bdca-3166f6c239f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminaries\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import losses\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Silence warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d186dd-c146-4ad1-a837-318c3e5fa94a",
   "metadata": {},
   "source": [
    "Some functions which will be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01235e13-86a7-482f-be93-cfde32ba2a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic functions\n",
    "def logistic1(x):\n",
    "  return 1/(1+math.exp(-x))\n",
    "logistic=np.vectorize(logistic1)\n",
    "def logit1(x):\n",
    "  return math.log(x/(1-x))\n",
    "logit=np.vectorize(logit1)\n",
    "\n",
    "# Sensitivity and specificity at range of cutoffs\n",
    "def roc_xy(ypred,y):\n",
    "    yt=sum(y); yl=len(y)\n",
    "    opred=np.argsort(ypred) \n",
    "    sy=y[opred]; sp=ypred[opred]\n",
    "\n",
    "    sens=1- (np.cumsum(sy)/yt)\n",
    "    spec=np.cumsum(1-sy)/(yl-yt)\n",
    "    \n",
    "    # coarsen; choose points regularly along arc length. Need to translate from R to be used\n",
    "    #if (!is.null(res)) {\n",
    "    # ds=cumsum(sqrt((spec0[1:(yl-1)]-spec0[2:yl])^2 + (sens0[1:(yl-1)]-sens0[2:yl])^2))\n",
    "    #  ds=ds/ds[yl-1]\n",
    "    #  lsp=(1:(yl-1))/yl\n",
    "    #  sub=round(yl*approx(ds,lsp,n=res)$y)\n",
    "    #  sens0=sens0[sub]\n",
    "    #  spec0=spec0[sub]\n",
    "    # }\n",
    "    \n",
    "    return np.column_stack((sens,spec))\n",
    "\n",
    "# Return a system command to generate synthetic data\n",
    "def syscom_synth(opath,spath,epath,train_name,test_name,target_name,model_type,extra,dp_e,dp_d):\n",
    "    out=\"python \"+ epath + \"evaluate.py \"+\\\n",
    "    \"--train-data-path=\"+opath+train_name+\" \"+\\\n",
    "    \"--test-data-path=\"+opath+test_name+\" \"+\\\n",
    "    \"--target-variable=\"+target_name+\" \"+\\\n",
    "    \"--normalize-data \"+model_type+\" \"+\\\n",
    "    \"--save-synthetic --output-data-path=\"+spath+\" \"+\\\n",
    "    extra\n",
    "    if dp_e>0:\n",
    "        out=out+\" --enable-privacy --target-epsilon=\"+str(dp_e)\n",
    "    if dp_d>0:\n",
    "        out=out+\" --target-delta=\"+str(dp_d)\n",
    "    return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe85f39-cd2b-4a01-8185-7b6632cff4b2",
   "metadata": {},
   "source": [
    "Now we generate basic data which we will try and mimic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61c84d0b-17c4-4d37-8866-c31b30781c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate covariate data\n",
    "cov_train=np.reshape(np.random.uniform(mu,sigma,p*nx),(nx,p))\n",
    "cov_test=np.reshape(np.random.uniform(mu,sigma,p*nx),(nx,p))\n",
    "\n",
    "# Generate outcome data\n",
    "p_train=logistic(np.matmul(cov_train,beta))\n",
    "p_test=logistic(np.matmul(cov_test,beta))\n",
    "y_train=np.random.binomial(1,p_train,nx)\n",
    "y_test=np.random.binomial(1,p_test,nx)\n",
    "\n",
    "# Combine covariates and outcome\n",
    "dat_train=np.column_stack((cov_train,y_train))\n",
    "dat_test=np.column_stack((cov_test,y_test))\n",
    "\n",
    "# Glimpse\n",
    "#print(dat_train[-5:])\n",
    "#print(dat_test[-5:])\n",
    "\n",
    "# Column names\n",
    "dat_colnames=[\"X1\",\"X2\",\"X3\",\"X4\",\"Y\"]\n",
    "\n",
    "# Write to file\n",
    "with open(orig_path+'simple_logistic/simple_logistic_train.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(dat_colnames)\n",
    "    writer.writerows(dat_train)\n",
    "    f.close()\n",
    "with open(orig_path+'simple_logistic/simple_logistic_test.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(dat_colnames)\n",
    "    writer.writerows(dat_test)\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd3609-4e46-40da-a803-0adb03143d5d",
   "metadata": {},
   "source": [
    "Now we will generate some synthetic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4009f7a-9026-4723-b35e-291fe99e5319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 Loss D real :  0.010004842751304933 Loss D fake :  0.01021959553428624 Loss G :  0.010221034648433948 Epsilon spent :  0\n",
      "Epoch : 2 Loss D real :  0.01001019431213099 Loss D fake :  0.01031713255088497 Loss G :  0.010391900416734445 Epsilon spent :  0\n",
      "Epoch : 3 Loss D real :  0.01001269151633474 Loss D fake :  0.010349834791899982 Loss G :  0.01031648252920215 Epsilon spent :  0\n",
      "Epoch : 4 Loss D real :  0.010018423280951337 Loss D fake :  0.010261910675061296 Loss G :  0.010255001245511278 Epsilon spent :  0\n",
      "Epoch : 5 Loss D real :  0.010016987941581876 Loss D fake :  0.010298242360388055 Loss G :  0.010280615077115493 Epsilon spent :  0\n",
      "Epoch : 6 Loss D real :  0.010015553903021399 Loss D fake :  0.01021927611167537 Loss G :  0.010288772667981975 Epsilon spent :  0\n",
      "Epoch : 7 Loss D real :  0.010009664096991942 Loss D fake :  0.010273237735192266 Loss G :  0.010307381378260788 Epsilon spent :  0\n",
      "Epoch : 8 Loss D real :  0.01000923785138145 Loss D fake :  0.01030795885444635 Loss G :  0.01037364689750829 Epsilon spent :  0\n",
      "Epoch : 9 Loss D real :  0.01001238538320479 Loss D fake :  0.010259633002902791 Loss G :  0.010273258997649325 Epsilon spent :  0\n",
      "Epoch : 10 Loss D real :  0.010010485687350721 Loss D fake :  0.010261884347867335 Loss G :  0.010300234684976017 Epsilon spent :  0\n",
      "Epoch : 11 Loss D real :  0.010009996364895125 Loss D fake :  0.010295658265203957 Loss G :  0.010240830276394596 Epsilon spent :  0\n",
      "Epoch : 12 Loss D real :  0.01001202047494924 Loss D fake :  0.010246884572132853 Loss G :  0.010318707259620422 Epsilon spent :  0\n",
      "Epoch : 13 Loss D real :  0.010008373994459292 Loss D fake :  0.010259630842365449 Loss G :  0.010329630601708745 Epsilon spent :  0\n",
      "Epoch : 14 Loss D real :  0.010005323978985497 Loss D fake :  0.0102616335939636 Loss G :  0.010295132486381501 Epsilon spent :  0\n",
      "Epoch : 15 Loss D real :  0.010012717138616928 Loss D fake :  0.010290571410934118 Loss G :  0.010254926129851797 Epsilon spent :  0\n",
      "Epoch : 16 Loss D real :  0.010010767592853043 Loss D fake :  0.010247924394464838 Loss G :  0.010288098478005667 Epsilon spent :  0\n",
      "Epoch : 17 Loss D real :  0.010005737904577627 Loss D fake :  0.010260945914205047 Loss G :  0.010267802982469366 Epsilon spent :  0\n",
      "Epoch : 18 Loss D real :  0.010008545658174689 Loss D fake :  0.010259421573636142 Loss G :  0.010279556533466443 Epsilon spent :  0\n",
      "Epoch : 19 Loss D real :  0.010009241745964076 Loss D fake :  0.01029453067156064 Loss G :  0.010257308151937972 Epsilon spent :  0\n",
      "Epoch : 20 Loss D real :  0.010008182835370232 Loss D fake :  0.01026231427232523 Loss G :  0.01031020811670889 Epsilon spent :  0\n",
      "Epoch : 21 Loss D real :  0.010006220915075598 Loss D fake :  0.010322988734538407 Loss G :  0.0102216782991701 Epsilon spent :  0\n",
      "Epoch : 22 Loss D real :  0.010009364369260629 Loss D fake :  0.010287478587953421 Loss G :  0.01023668117701259 Epsilon spent :  0\n",
      "Epoch : 23 Loss D real :  0.010002238190749902 Loss D fake :  0.010225634620885883 Loss G :  0.010252185401406304 Epsilon spent :  0\n",
      "Epoch : 24 Loss D real :  0.010003353119649274 Loss D fake :  0.01026791019467097 Loss G :  0.010254939660066527 Epsilon spent :  0\n",
      "Epoch : 25 Loss D real :  0.010007300584555047 Loss D fake :  0.010224922273208863 Loss G :  0.010238583346257242 Epsilon spent :  0\n",
      "Epoch : 26 Loss D real :  0.010008128115648765 Loss D fake :  0.010251256079907888 Loss G :  0.010240863194196603 Epsilon spent :  0\n",
      "Epoch : 27 Loss D real :  0.010007592774960501 Loss D fake :  0.010246200210594813 Loss G :  0.01021755409115735 Epsilon spent :  0\n",
      "Epoch : 28 Loss D real :  0.010007034899391865 Loss D fake :  0.0102770563914023 Loss G :  0.010236023271083564 Epsilon spent :  0\n",
      "Epoch : 29 Loss D real :  0.010006206838662275 Loss D fake :  0.010232010040669213 Loss G :  0.010227511324727422 Epsilon spent :  0\n",
      "Epoch : 30 Loss D real :  0.010004289447911447 Loss D fake :  0.01021469587227549 Loss G :  0.01026503503497742 Epsilon spent :  0\n",
      "Epoch : 31 Loss D real :  0.010003247956968235 Loss D fake :  0.010256373189404373 Loss G :  0.010227981183181896 Epsilon spent :  0\n",
      "Epoch : 32 Loss D real :  0.01000762146891445 Loss D fake :  0.010235907850020532 Loss G :  0.010298888295395792 Epsilon spent :  0\n",
      "Epoch : 33 Loss D real :  0.010005265263033114 Loss D fake :  0.010247470177289763 Loss G :  0.01024939263306701 Epsilon spent :  0\n",
      "Epoch : 34 Loss D real :  0.010006429207931107 Loss D fake :  0.010248514290501526 Loss G :  0.010241340531878196 Epsilon spent :  0\n",
      "Epoch : 35 Loss D real :  0.010002737153696924 Loss D fake :  0.010237032328855096 Loss G :  0.010214157633216288 Epsilon spent :  0\n",
      "Epoch : 36 Loss D real :  0.010010665735019488 Loss D fake :  0.01023104909061531 Loss G :  0.010199970426836569 Epsilon spent :  0\n",
      "Epoch : 37 Loss D real :  0.01000397445932588 Loss D fake :  0.010203828915188435 Loss G :  0.010262124033315782 Epsilon spent :  0\n",
      "Epoch : 38 Loss D real :  0.01000586321034954 Loss D fake :  0.010235867467513763 Loss G :  0.010258930225977665 Epsilon spent :  0\n",
      "Epoch : 39 Loss D real :  0.010004347591734367 Loss D fake :  0.010202809066684491 Loss G :  0.010288723380339503 Epsilon spent :  0\n",
      "Epoch : 40 Loss D real :  0.010005906778917995 Loss D fake :  0.010223174270784086 Loss G :  0.010254612857331258 Epsilon spent :  0\n",
      "Epoch : 41 Loss D real :  0.010008890159154295 Loss D fake :  0.010236027345390836 Loss G :  0.010170327438562863 Epsilon spent :  0\n",
      "Epoch : 42 Loss D real :  0.010006348311152423 Loss D fake :  0.010212587956433813 Loss G :  0.01022630964704804 Epsilon spent :  0\n",
      "Epoch : 43 Loss D real :  0.010004491194146453 Loss D fake :  0.010246815825230647 Loss G :  0.010214866392088436 Epsilon spent :  0\n",
      "Epoch : 44 Loss D real :  0.01000707759945936 Loss D fake :  0.010189358959838066 Loss G :  0.010262567014245504 Epsilon spent :  0\n",
      "Epoch : 45 Loss D real :  0.01000552107638818 Loss D fake :  0.010266239181957768 Loss G :  0.010229936424757143 Epsilon spent :  0\n",
      "Epoch : 46 Loss D real :  0.010003919804405145 Loss D fake :  0.010201927316976245 Loss G :  0.010194428765458348 Epsilon spent :  0\n",
      "Epoch : 47 Loss D real :  0.010004924165247488 Loss D fake :  0.010217914290012526 Loss G :  0.010217901972405147 Epsilon spent :  0\n",
      "Epoch : 48 Loss D real :  0.010005678589989794 Loss D fake :  0.01019502747039144 Loss G :  0.010175574397667997 Epsilon spent :  0\n",
      "Epoch : 49 Loss D real :  0.010007841536033292 Loss D fake :  0.010203100666905576 Loss G :  0.010194749904728321 Epsilon spent :  0\n",
      "Epoch : 50 Loss D real :  0.010006003015547965 Loss D fake :  0.010188664236437496 Loss G :  0.010212791109379404 Epsilon spent :  0\n",
      "Epoch : 51 Loss D real :  0.010003333131413328 Loss D fake :  0.010256144685484123 Loss G :  0.010232964202265224 Epsilon spent :  0\n",
      "Epoch : 52 Loss D real :  0.010004406960257345 Loss D fake :  0.010217909684377035 Loss G :  0.010142590702941247 Epsilon spent :  0\n",
      "Epoch : 53 Loss D real :  0.010008314022537917 Loss D fake :  0.010195445767946018 Loss G :  0.010183693937623 Epsilon spent :  0\n",
      "Epoch : 54 Loss D real :  0.010006326790541947 Loss D fake :  0.01020313895412904 Loss G :  0.010213016462099028 Epsilon spent :  0\n",
      "Epoch : 55 Loss D real :  0.010004997973360274 Loss D fake :  0.01018298949315293 Loss G :  0.01020165034185088 Epsilon spent :  0\n",
      "Epoch : 56 Loss D real :  0.010004463505616108 Loss D fake :  0.010205539329683664 Loss G :  0.010186663027407672 Epsilon spent :  0\n",
      "Epoch : 57 Loss D real :  0.010006130234924564 Loss D fake :  0.010195248554993225 Loss G :  0.010208726972636365 Epsilon spent :  0\n",
      "Epoch : 58 Loss D real :  0.010008272594526291 Loss D fake :  0.010207761270768563 Loss G :  0.010218331692411502 Epsilon spent :  0\n",
      "Epoch : 59 Loss D real :  0.010004268814017852 Loss D fake :  0.010142130092481421 Loss G :  0.01016230877187288 Epsilon spent :  0\n",
      "Epoch : 60 Loss D real :  0.010005213951290115 Loss D fake :  0.01024294446142346 Loss G :  0.010181379085702751 Epsilon spent :  0\n",
      "Epoch : 61 Loss D real :  0.010004537762010372 Loss D fake :  0.01018512862345364 Loss G :  0.010200973128020045 Epsilon spent :  0\n",
      "Epoch : 62 Loss D real :  0.01000247373861778 Loss D fake :  0.010193722476981162 Loss G :  0.010194287506980957 Epsilon spent :  0\n",
      "Epoch : 63 Loss D real :  0.010005462051016729 Loss D fake :  0.0101646041632052 Loss G :  0.010169981532146316 Epsilon spent :  0\n",
      "Epoch : 64 Loss D real :  0.010005360212893439 Loss D fake :  0.010168234779744146 Loss G :  0.010189356836272105 Epsilon spent :  0\n",
      "Epoch : 65 Loss D real :  0.010009409002858443 Loss D fake :  0.010177693518258386 Loss G :  0.010140204193488569 Epsilon spent :  0\n",
      "Epoch : 66 Loss D real :  0.010004755399213796 Loss D fake :  0.010173078142561204 Loss G :  0.010205035718975953 Epsilon spent :  0\n",
      "Epoch : 67 Loss D real :  0.010003473169799609 Loss D fake :  0.010185447460919836 Loss G :  0.010185194223551948 Epsilon spent :  0\n",
      "Epoch : 68 Loss D real :  0.010005472688992741 Loss D fake :  0.010130133003247948 Loss G :  0.010194241116726512 Epsilon spent :  0\n",
      "Epoch : 69 Loss D real :  0.010001918334135978 Loss D fake :  0.010182256176387305 Loss G :  0.010205791974932689 Epsilon spent :  0\n",
      "Epoch : 70 Loss D real :  0.010002295044794524 Loss D fake :  0.010159961547744957 Loss G :  0.010162799028964897 Epsilon spent :  0\n",
      "Epoch : 71 Loss D real :  0.010000655423552442 Loss D fake :  0.010138326954753203 Loss G :  0.010179463422923224 Epsilon spent :  0\n",
      "Epoch : 72 Loss D real :  0.010002693630774634 Loss D fake :  0.010214311365411323 Loss G :  0.01016731470711442 Epsilon spent :  0\n",
      "Epoch : 73 Loss D real :  0.010005905130013574 Loss D fake :  0.010189077184276722 Loss G :  0.010156655782611124 Epsilon spent :  0\n",
      "Epoch : 74 Loss D real :  0.010006328361950624 Loss D fake :  0.010173940308815719 Loss G :  0.010170613980811778 Epsilon spent :  0\n",
      "Epoch : 75 Loss D real :  0.010007863569869385 Loss D fake :  0.010175322312797008 Loss G :  0.01015928028365473 Epsilon spent :  0\n",
      "Epoch : 76 Loss D real :  0.010005040195612956 Loss D fake :  0.01016259368049802 Loss G :  0.010144687423595571 Epsilon spent :  0\n",
      "Epoch : 77 Loss D real :  0.010003092120973809 Loss D fake :  0.010133514811031353 Loss G :  0.010171649504227961 Epsilon spent :  0\n",
      "Epoch : 78 Loss D real :  0.010006320884368139 Loss D fake :  0.010135076976291475 Loss G :  0.010151954244192385 Epsilon spent :  0\n",
      "Epoch : 79 Loss D real :  0.010002939213630905 Loss D fake :  0.010160256227066771 Loss G :  0.010184954243277707 Epsilon spent :  0\n",
      "Epoch : 80 Loss D real :  0.01000369584103065 Loss D fake :  0.01019293178712297 Loss G :  0.010141349271679697 Epsilon spent :  0\n",
      "Epoch : 81 Loss D real :  0.010005068859509268 Loss D fake :  0.010170125216786337 Loss G :  0.0101323005726047 Epsilon spent :  0\n",
      "Epoch : 82 Loss D real :  0.010011060802578643 Loss D fake :  0.010207334587066944 Loss G :  0.01014163222470265 Epsilon spent :  0\n",
      "Epoch : 83 Loss D real :  0.010004405653976443 Loss D fake :  0.010173138635334674 Loss G :  0.0101344683245324 Epsilon spent :  0\n",
      "Epoch : 84 Loss D real :  0.010009979098701188 Loss D fake :  0.010137013906269409 Loss G :  0.010153639410048817 Epsilon spent :  0\n",
      "Epoch : 85 Loss D real :  0.010006306380837372 Loss D fake :  0.010119377736251566 Loss G :  0.010137475585874672 Epsilon spent :  0\n",
      "Epoch : 86 Loss D real :  0.010004894594997867 Loss D fake :  0.010160503424864542 Loss G :  0.010145875664207726 Epsilon spent :  0\n",
      "Epoch : 87 Loss D real :  0.010006374235370482 Loss D fake :  0.010116036760521255 Loss G :  0.010162798767881108 Epsilon spent :  0\n",
      "Epoch : 88 Loss D real :  0.010005819510130964 Loss D fake :  0.010128448548660565 Loss G :  0.010182722559949972 Epsilon spent :  0\n",
      "Epoch : 89 Loss D real :  0.010006239871668602 Loss D fake :  0.010145199581094003 Loss G :  0.010127699194217143 Epsilon spent :  0\n",
      "Epoch : 90 Loss D real :  0.010002853876526767 Loss D fake :  0.010147218077744574 Loss G :  0.010162391547511937 Epsilon spent :  0\n",
      "Epoch : 91 Loss D real :  0.010000342068489142 Loss D fake :  0.010119574733527571 Loss G :  0.010124645479744059 Epsilon spent :  0\n",
      "Epoch : 92 Loss D real :  0.010002364122129714 Loss D fake :  0.010142430265318483 Loss G :  0.010134323977901993 Epsilon spent :  0\n",
      "Epoch : 93 Loss D real :  0.010002776160817649 Loss D fake :  0.010124165958939009 Loss G :  0.010188468108749828 Epsilon spent :  0\n",
      "Epoch : 94 Loss D real :  0.010006588347106772 Loss D fake :  0.010115493365471939 Loss G :  0.010139083407638432 Epsilon spent :  0\n",
      "Epoch : 95 Loss D real :  0.01000674948967638 Loss D fake :  0.010116024453604483 Loss G :  0.010140614765949414 Epsilon spent :  0\n",
      "Epoch : 96 Loss D real :  0.010004572129128819 Loss D fake :  0.010131798935116709 Loss G :  0.010132529912517329 Epsilon spent :  0\n",
      "Epoch : 97 Loss D real :  0.010003887746130879 Loss D fake :  0.01014521992104311 Loss G :  0.010117111613549452 Epsilon spent :  0\n",
      "Epoch : 98 Loss D real :  0.010007588151557846 Loss D fake :  0.010137720177871668 Loss G :  0.010111612378404354 Epsilon spent :  0\n",
      "Epoch : 99 Loss D real :  0.010008562038684617 Loss D fake :  0.01012142290384081 Loss G :  0.010158045842306162 Epsilon spent :  0\n",
      "Epoch : 100 Loss D real :  0.01000691145846763 Loss D fake :  0.01014179174077798 Loss G :  0.010122106814353429 Epsilon spent :  0\n",
      "Epoch : 101 Loss D real :  0.010006488702497157 Loss D fake :  0.010111345311921767 Loss G :  0.010116990959068968 Epsilon spent :  0\n",
      "Epoch : 102 Loss D real :  0.010003999402052552 Loss D fake :  0.010125253627074124 Loss G :  0.01011653403482902 Epsilon spent :  0\n",
      "Epoch : 103 Loss D real :  0.010005820378331799 Loss D fake :  0.010103441891819064 Loss G :  0.010066219083191753 Epsilon spent :  0\n",
      "Epoch : 104 Loss D real :  0.010008159037327106 Loss D fake :  0.010132910875779503 Loss G :  0.010135173192385685 Epsilon spent :  0\n",
      "Epoch : 105 Loss D real :  0.010004183302541497 Loss D fake :  0.01008917960502189 Loss G :  0.010133832412760056 Epsilon spent :  0\n",
      "Epoch : 106 Loss D real :  0.010002646639261445 Loss D fake :  0.01011547519447694 Loss G :  0.010122249558963332 Epsilon spent :  0\n",
      "Epoch : 107 Loss D real :  0.010004683364144536 Loss D fake :  0.01010711119740256 Loss G :  0.010151132348824789 Epsilon spent :  0\n",
      "Epoch : 108 Loss D real :  0.010008349054380111 Loss D fake :  0.01011325372454629 Loss G :  0.01011146331741612 Epsilon spent :  0\n",
      "Epoch : 109 Loss D real :  0.010004238016140416 Loss D fake :  0.010123470696175519 Loss G :  0.010133607148602123 Epsilon spent :  0\n",
      "Epoch : 110 Loss D real :  0.01000770530384364 Loss D fake :  0.010134835562418773 Loss G :  0.01012392285927893 Epsilon spent :  0\n",
      "Epoch : 111 Loss D real :  0.010011387285901927 Loss D fake :  0.010106392402408319 Loss G :  0.01011293166243004 Epsilon spent :  0\n",
      "Epoch : 112 Loss D real :  0.010003847416725649 Loss D fake :  0.010133710884233671 Loss G :  0.010121811453596509 Epsilon spent :  0\n",
      "Epoch : 113 Loss D real :  0.010010903662376081 Loss D fake :  0.010104490654418655 Loss G :  0.010080869353820984 Epsilon spent :  0\n",
      "Epoch : 114 Loss D real :  0.01000330219130103 Loss D fake :  0.010106924895724472 Loss G :  0.010115367230752702 Epsilon spent :  0\n",
      "Epoch : 115 Loss D real :  0.010002793827141292 Loss D fake :  0.010082823106236597 Loss G :  0.01013279932782147 Epsilon spent :  0\n",
      "Epoch : 116 Loss D real :  0.010005638124896205 Loss D fake :  0.010116698991602384 Loss G :  0.01008996385660961 Epsilon spent :  0\n",
      "Epoch : 117 Loss D real :  0.010001984081882348 Loss D fake :  0.010091173538479666 Loss G :  0.010115188534109044 Epsilon spent :  0\n",
      "Epoch : 118 Loss D real :  0.01000643694640487 Loss D fake :  0.01010853784692234 Loss G :  0.010104910375233618 Epsilon spent :  0\n",
      "Epoch : 119 Loss D real :  0.01000309681812368 Loss D fake :  0.010084413102533732 Loss G :  0.010116881001684709 Epsilon spent :  0\n",
      "Epoch : 120 Loss D real :  0.01000474025842016 Loss D fake :  0.010085922231678675 Loss G :  0.010092469081385601 Epsilon spent :  0\n",
      "Epoch : 121 Loss D real :  0.010006384194308918 Loss D fake :  0.010092790980433832 Loss G :  0.010113070222392594 Epsilon spent :  0\n",
      "Epoch : 122 Loss D real :  0.010004905448878413 Loss D fake :  0.010114704259021997 Loss G :  0.01010330947180885 Epsilon spent :  0\n",
      "Epoch : 123 Loss D real :  0.010002238456229287 Loss D fake :  0.010115699338388101 Loss G :  0.010095838812107258 Epsilon spent :  0\n",
      "Epoch : 124 Loss D real :  0.010007469432306272 Loss D fake :  0.010093323260530328 Loss G :  0.010106810527198397 Epsilon spent :  0\n",
      "Epoch : 125 Loss D real :  0.010003495612551067 Loss D fake :  0.010104899043178801 Loss G :  0.010114258614175108 Epsilon spent :  0\n",
      "Epoch : 126 Loss D real :  0.01000308933001778 Loss D fake :  0.010113891182017649 Loss G :  0.010097504911284024 Epsilon spent :  0\n",
      "Epoch : 127 Loss D real :  0.010004111922875909 Loss D fake :  0.010117492187907895 Loss G :  0.010097057803128157 Epsilon spent :  0\n",
      "Epoch : 128 Loss D real :  0.010006991934425667 Loss D fake :  0.010108692155675338 Loss G :  0.010086907877902552 Epsilon spent :  0\n",
      "Epoch : 129 Loss D real :  0.010007271454765791 Loss D fake :  0.010076122803285043 Loss G :  0.010101406730726587 Epsilon spent :  0\n",
      "Epoch : 130 Loss D real :  0.010002614406108052 Loss D fake :  0.010075386249817402 Loss G :  0.010089532415730304 Epsilon spent :  0\n",
      "Epoch : 131 Loss D real :  0.01000374707692223 Loss D fake :  0.01009322961120434 Loss G :  0.010103245590557032 Epsilon spent :  0\n",
      "Epoch : 132 Loss D real :  0.010005453721272546 Loss D fake :  0.010091878362887288 Loss G :  0.010075135437864459 Epsilon spent :  0\n",
      "Epoch : 133 Loss D real :  0.01000309166801232 Loss D fake :  0.01007676345850572 Loss G :  0.010080379628455639 Epsilon spent :  0\n",
      "Epoch : 134 Loss D real :  0.010006145551663452 Loss D fake :  0.010095526646928915 Loss G :  0.010082890018723943 Epsilon spent :  0\n",
      "Epoch : 135 Loss D real :  0.010006553878844112 Loss D fake :  0.010097739232854758 Loss G :  0.010069617342297952 Epsilon spent :  0\n",
      "Epoch : 136 Loss D real :  0.010005435913412991 Loss D fake :  0.01007774178204626 Loss G :  0.010086671836567286 Epsilon spent :  0\n",
      "Epoch : 137 Loss D real :  0.010004021838842064 Loss D fake :  0.010073356632018738 Loss G :  0.010087385297839337 Epsilon spent :  0\n",
      "Epoch : 138 Loss D real :  0.010004862746678918 Loss D fake :  0.010089270500914668 Loss G :  0.010078971017502466 Epsilon spent :  0\n",
      "Epoch : 139 Loss D real :  0.010003896880032786 Loss D fake :  0.01005997079424745 Loss G :  0.0100593147325541 Epsilon spent :  0\n",
      "Epoch : 140 Loss D real :  0.010007124212830378 Loss D fake :  0.010100036664403674 Loss G :  0.010062413134678096 Epsilon spent :  0\n",
      "Epoch : 141 Loss D real :  0.010003482197687241 Loss D fake :  0.010096498516536009 Loss G :  0.010070090150445453 Epsilon spent :  0\n",
      "Epoch : 142 Loss D real :  0.010005130603370398 Loss D fake :  0.010088250838308525 Loss G :  0.010106176039454807 Epsilon spent :  0\n",
      "Epoch : 143 Loss D real :  0.010001958234450818 Loss D fake :  0.010064619810630138 Loss G :  0.010090513887487504 Epsilon spent :  0\n",
      "Epoch : 144 Loss D real :  0.01000267087184804 Loss D fake :  0.010081757682738715 Loss G :  0.010070410117375004 Epsilon spent :  0\n",
      "Epoch : 145 Loss D real :  0.01000415464946032 Loss D fake :  0.010081147303904437 Loss G :  0.01008858016813027 Epsilon spent :  0\n",
      "Epoch : 146 Loss D real :  0.010004597440656123 Loss D fake :  0.010097282353561382 Loss G :  0.010055141532557262 Epsilon spent :  0\n",
      "Epoch : 147 Loss D real :  0.010001802248502152 Loss D fake :  0.010065586593516493 Loss G :  0.01008666248384426 Epsilon spent :  0\n",
      "Epoch : 148 Loss D real :  0.010002440579151048 Loss D fake :  0.010093688360478909 Loss G :  0.010079425947467415 Epsilon spent :  0\n",
      "Epoch : 149 Loss D real :  0.010003847765889471 Loss D fake :  0.010054688539975935 Loss G :  0.010087528196390878 Epsilon spent :  0\n",
      "Epoch : 150 Loss D real :  0.010003976692500601 Loss D fake :  0.010065402467929566 Loss G :  0.010068852845650083 Epsilon spent :  0\n",
      "Epoch : 151 Loss D real :  0.010002979081681882 Loss D fake :  0.010061284288358424 Loss G :  0.010062404477512835 Epsilon spent :  0\n",
      "Epoch : 152 Loss D real :  0.01000590110668478 Loss D fake :  0.010080349047728962 Loss G :  0.010068882155289144 Epsilon spent :  0\n",
      "Epoch : 153 Loss D real :  0.010003697574532192 Loss D fake :  0.010076621712895206 Loss G :  0.010080771896161595 Epsilon spent :  0\n",
      "Epoch : 154 Loss D real :  0.010001595353158836 Loss D fake :  0.010080621097069808 Loss G :  0.010073730429168105 Epsilon spent :  0\n",
      "Epoch : 155 Loss D real :  0.010003123942530235 Loss D fake :  0.010060818621996266 Loss G :  0.010074125371111298 Epsilon spent :  0\n",
      "Epoch : 156 Loss D real :  0.01000299338831771 Loss D fake :  0.010075095536002821 Loss G :  0.01006616755000248 Epsilon spent :  0\n",
      "Epoch : 157 Loss D real :  0.010005108006980401 Loss D fake :  0.010051947521964085 Loss G :  0.010072537079063394 Epsilon spent :  0\n",
      "Epoch : 158 Loss D real :  0.010003566422185807 Loss D fake :  0.010054931878067141 Loss G :  0.010056366121942169 Epsilon spent :  0\n",
      "Epoch : 159 Loss D real :  0.010003698180554483 Loss D fake :  0.01006181288462604 Loss G :  0.010062455384094202 Epsilon spent :  0\n",
      "Epoch : 160 Loss D real :  0.010006124089274059 Loss D fake :  0.010042644741810486 Loss G :  0.010058297672585268 Epsilon spent :  0\n",
      "Epoch : 161 Loss D real :  0.010009185145127698 Loss D fake :  0.010052976478842186 Loss G :  0.010066604299079684 Epsilon spent :  0\n",
      "Epoch : 162 Loss D real :  0.010001027375478911 Loss D fake :  0.010064894612197662 Loss G :  0.010061408607596169 Epsilon spent :  0\n",
      "Epoch : 163 Loss D real :  0.010001190948925882 Loss D fake :  0.010079578249744476 Loss G :  0.010062075855549874 Epsilon spent :  0\n",
      "Epoch : 164 Loss D real :  0.010002999681234087 Loss D fake :  0.010047862159469838 Loss G :  0.010054040660826394 Epsilon spent :  0\n",
      "Epoch : 165 Loss D real :  0.010004575750948467 Loss D fake :  0.010046114054907306 Loss G :  0.01004939322159168 Epsilon spent :  0\n",
      "Epoch : 166 Loss D real :  0.010003632342156071 Loss D fake :  0.010062628938937617 Loss G :  0.010053911164852292 Epsilon spent :  0\n",
      "Epoch : 167 Loss D real :  0.01000276556480439 Loss D fake :  0.01006999592971801 Loss G :  0.010067321625974877 Epsilon spent :  0\n",
      "Epoch : 168 Loss D real :  0.010003304198205224 Loss D fake :  0.01006187833906725 Loss G :  0.01005587528128068 Epsilon spent :  0\n",
      "Epoch : 169 Loss D real :  0.010003872367094173 Loss D fake :  0.010069321222478472 Loss G :  0.010048968707796705 Epsilon spent :  0\n",
      "Epoch : 170 Loss D real :  0.010007475000241513 Loss D fake :  0.01006615553412796 Loss G :  0.010045577922367259 Epsilon spent :  0\n",
      "Epoch : 171 Loss D real :  0.010002782320698523 Loss D fake :  0.01004898108314499 Loss G :  0.010062797939923268 Epsilon spent :  0\n",
      "Epoch : 172 Loss D real :  0.010002256615927926 Loss D fake :  0.010060739785353174 Loss G :  0.01005972796117088 Epsilon spent :  0\n",
      "Epoch : 173 Loss D real :  0.010001852764935325 Loss D fake :  0.010057864498731394 Loss G :  0.010054510693629814 Epsilon spent :  0\n",
      "Epoch : 174 Loss D real :  0.010004210114567064 Loss D fake :  0.010065149291285764 Loss G :  0.010063913587656783 Epsilon spent :  0\n",
      "Epoch : 175 Loss D real :  0.010001067843868604 Loss D fake :  0.010040290733839018 Loss G :  0.010040277764067159 Epsilon spent :  0\n",
      "Epoch : 176 Loss D real :  0.010005202784802795 Loss D fake :  0.010035523064337259 Loss G :  0.010053396955599508 Epsilon spent :  0\n",
      "Epoch : 177 Loss D real :  0.01000291582895787 Loss D fake :  0.010039243640846405 Loss G :  0.01005210189396937 Epsilon spent :  0\n",
      "Epoch : 178 Loss D real :  0.0100011070673442 Loss D fake :  0.01004509721913846 Loss G :  0.010055848774855432 Epsilon spent :  0\n",
      "Epoch : 179 Loss D real :  0.010004199751975095 Loss D fake :  0.01005283424312827 Loss G :  0.010058269772304701 Epsilon spent :  0\n",
      "Epoch : 180 Loss D real :  0.010005199815631971 Loss D fake :  0.010047470826103815 Loss G :  0.010051058733139653 Epsilon spent :  0\n",
      "Epoch : 181 Loss D real :  0.010002189375226558 Loss D fake :  0.01007008226889813 Loss G :  0.010045047422072566 Epsilon spent :  0\n",
      "Epoch : 182 Loss D real :  0.01000321788830378 Loss D fake :  0.01003970049776871 Loss G :  0.010029694119580065 Epsilon spent :  0\n",
      "Epoch : 183 Loss D real :  0.010003505189245466 Loss D fake :  0.010026292263610757 Loss G :  0.01004856699806245 Epsilon spent :  0\n",
      "Epoch : 184 Loss D real :  0.010008002942768218 Loss D fake :  0.010038762408798162 Loss G :  0.01004887033989548 Epsilon spent :  0\n",
      "Epoch : 185 Loss D real :  0.010002527456537428 Loss D fake :  0.010048555668663636 Loss G :  0.010057888514681274 Epsilon spent :  0\n",
      "Epoch : 186 Loss D real :  0.01000471678131833 Loss D fake :  0.010032138172323062 Loss G :  0.010044700605839367 Epsilon spent :  0\n",
      "Epoch : 187 Loss D real :  0.010001715759080302 Loss D fake :  0.01004335179174406 Loss G :  0.010052573380624295 Epsilon spent :  0\n",
      "Epoch : 188 Loss D real :  0.010006453646978953 Loss D fake :  0.01002687654494393 Loss G :  0.010045771085846039 Epsilon spent :  0\n",
      "Epoch : 189 Loss D real :  0.010004792956364547 Loss D fake :  0.010037261606028688 Loss G :  0.010044603150054388 Epsilon spent :  0\n",
      "Epoch : 190 Loss D real :  0.010004573615358427 Loss D fake :  0.010047688677137668 Loss G :  0.010041064767918597 Epsilon spent :  0\n",
      "Epoch : 191 Loss D real :  0.010001826658674209 Loss D fake :  0.010044098976801951 Loss G :  0.010051599718208943 Epsilon spent :  0\n",
      "Epoch : 192 Loss D real :  0.010004809900349305 Loss D fake :  0.010041220088419681 Loss G :  0.010036665676069537 Epsilon spent :  0\n",
      "Epoch : 193 Loss D real :  0.010003086620220269 Loss D fake :  0.010047423850040524 Loss G :  0.010054229819025708 Epsilon spent :  0\n",
      "Epoch : 194 Loss D real :  0.010000853953645701 Loss D fake :  0.010046331580231846 Loss G :  0.010030562055588653 Epsilon spent :  0\n",
      "Epoch : 195 Loss D real :  0.010002108886443777 Loss D fake :  0.010047730271225755 Loss G :  0.010037000999539802 Epsilon spent :  0\n",
      "Epoch : 196 Loss D real :  0.010001593064175866 Loss D fake :  0.010047143630915634 Loss G :  0.010034058481857943 Epsilon spent :  0\n",
      "Epoch : 197 Loss D real :  0.010004335132407222 Loss D fake :  0.010029074664782868 Loss G :  0.010032901435667034 Epsilon spent :  0\n",
      "Epoch : 198 Loss D real :  0.010001689856590907 Loss D fake :  0.010040489047203727 Loss G :  0.010041971538454328 Epsilon spent :  0\n",
      "Epoch : 199 Loss D real :  0.010003053499497191 Loss D fake :  0.010042522755549241 Loss G :  0.010038264367342621 Epsilon spent :  0\n",
      "Epoch : 200 Loss D real :  0.01000089613126329 Loss D fake :  0.01003655015478569 Loss G :  0.010026774508149127 Epsilon spent :  0\n",
      "Epoch : 201 Loss D real :  0.010001743996747636 Loss D fake :  0.010043546897064503 Loss G :  0.010046747322097599 Epsilon spent :  0\n",
      "Epoch : 202 Loss D real :  0.010008936389432784 Loss D fake :  0.010034655258827208 Loss G :  0.010030492262833932 Epsilon spent :  0\n",
      "Epoch : 203 Loss D real :  0.010001310463813437 Loss D fake :  0.010038812715109919 Loss G :  0.010033363120543407 Epsilon spent :  0\n",
      "Epoch : 204 Loss D real :  0.010002494062507677 Loss D fake :  0.010040606819685277 Loss G :  0.010031979490715926 Epsilon spent :  0\n",
      "Epoch : 205 Loss D real :  0.01000365653439766 Loss D fake :  0.010036481966536654 Loss G :  0.010035878252898518 Epsilon spent :  0\n",
      "Epoch : 206 Loss D real :  0.01 Loss D fake :  0.010034651035932934 Loss G :  0.010036839750081215 Epsilon spent :  0\n",
      "Epoch : 207 Loss D real :  0.010002262280578409 Loss D fake :  0.010032479826287294 Loss G :  0.010019187082928694 Epsilon spent :  0\n",
      "Epoch : 208 Loss D real :  0.010004615881162634 Loss D fake :  0.01001767895957 Loss G :  0.010033682187575176 Epsilon spent :  0\n",
      "Epoch : 209 Loss D real :  0.010002577176249357 Loss D fake :  0.010041350925703622 Loss G :  0.010032627657691116 Epsilon spent :  0\n",
      "Epoch : 210 Loss D real :  0.010000250101937468 Loss D fake :  0.010039737814566583 Loss G :  0.010039861315648416 Epsilon spent :  0\n",
      "Epoch : 211 Loss D real :  0.010004036777352524 Loss D fake :  0.010036551386158304 Loss G :  0.010039092261630335 Epsilon spent :  0\n",
      "Epoch : 212 Loss D real :  0.010004781821008741 Loss D fake :  0.01003599215490774 Loss G :  0.010027027095501559 Epsilon spent :  0\n",
      "Epoch : 213 Loss D real :  0.010001038593947159 Loss D fake :  0.010022702589789191 Loss G :  0.0100296787758467 Epsilon spent :  0\n",
      "Epoch : 214 Loss D real :  0.01000086582968384 Loss D fake :  0.010030704797359496 Loss G :  0.010030488166765598 Epsilon spent :  0\n",
      "Epoch : 215 Loss D real :  0.0100043825808476 Loss D fake :  0.010013888290815376 Loss G :  0.010023839976879006 Epsilon spent :  0\n",
      "Epoch : 216 Loss D real :  0.01000337518432312 Loss D fake :  0.010032593053021774 Loss G :  0.010023515388640354 Epsilon spent :  0\n",
      "Epoch : 217 Loss D real :  0.010001414761669077 Loss D fake :  0.010022590600811749 Loss G :  0.01002367826844975 Epsilon spent :  0\n",
      "Epoch : 218 Loss D real :  0.010003580988805987 Loss D fake :  0.010033493174330676 Loss G :  0.010030960966381895 Epsilon spent :  0\n",
      "Epoch : 219 Loss D real :  0.010001222934588463 Loss D fake :  0.010022973734363387 Loss G :  0.010036275611071545 Epsilon spent :  0\n",
      "Epoch : 220 Loss D real :  0.010001588881713432 Loss D fake :  0.010026691264136205 Loss G :  0.010028066414557524 Epsilon spent :  0\n",
      "Epoch : 221 Loss D real :  0.010002573393998173 Loss D fake :  0.010032312322014864 Loss G :  0.010014915381571399 Epsilon spent :  0\n",
      "Epoch : 222 Loss D real :  0.010000954469717206 Loss D fake :  0.010030760951720664 Loss G :  0.010024779503313427 Epsilon spent :  0\n",
      "Epoch : 223 Loss D real :  0.010002791136609426 Loss D fake :  0.010014683420999463 Loss G :  0.010028105715856439 Epsilon spent :  0\n",
      "Epoch : 224 Loss D real :  0.01000179599530861 Loss D fake :  0.010023993889923949 Loss G :  0.010018648768843839 Epsilon spent :  0\n",
      "Epoch : 225 Loss D real :  0.01000091011182762 Loss D fake :  0.01003133847344583 Loss G :  0.010017285334301318 Epsilon spent :  0\n",
      "Epoch : 226 Loss D real :  0.01000259955186006 Loss D fake :  0.010011778608451146 Loss G :  0.010018648939054495 Epsilon spent :  0\n",
      "Epoch : 227 Loss D real :  0.010000212515352649 Loss D fake :  0.010018732332608892 Loss G :  0.010022903681374845 Epsilon spent :  0\n",
      "Epoch : 228 Loss D real :  0.010001898907192035 Loss D fake :  0.010027053030569198 Loss G :  0.010017577472575355 Epsilon spent :  0\n",
      "Epoch : 229 Loss D real :  0.010003389165916813 Loss D fake :  0.010020639235088127 Loss G :  0.010015941078572066 Epsilon spent :  0\n",
      "Epoch : 230 Loss D real :  0.01000188599413419 Loss D fake :  0.010017512664600716 Loss G :  0.010031888279715977 Epsilon spent :  0\n",
      "Epoch : 231 Loss D real :  0.010002036219435049 Loss D fake :  0.010020243497035997 Loss G :  0.010029631876226068 Epsilon spent :  0\n",
      "Epoch : 232 Loss D real :  0.01000450636155819 Loss D fake :  0.010020605661274924 Loss G :  0.010025223462889062 Epsilon spent :  0\n",
      "Epoch : 233 Loss D real :  0.01000041590768542 Loss D fake :  0.010021424108121667 Loss G :  0.010015796427678098 Epsilon spent :  0\n",
      "Epoch : 234 Loss D real :  0.010001309171064857 Loss D fake :  0.010016921989041585 Loss G :  0.010014100340505221 Epsilon spent :  0\n",
      "Epoch : 235 Loss D real :  0.010001666116286091 Loss D fake :  0.010016348064476587 Loss G :  0.010020963426459722 Epsilon spent :  0\n",
      "Epoch : 236 Loss D real :  0.01000084398391309 Loss D fake :  0.01002099678160833 Loss G :  0.01002255334530681 Epsilon spent :  0\n",
      "Epoch : 237 Loss D real :  0.010002753535295034 Loss D fake :  0.010017413533824841 Loss G :  0.010027129175983987 Epsilon spent :  0\n",
      "Epoch : 238 Loss D real :  0.010000440896974746 Loss D fake :  0.010016337062838521 Loss G :  0.010021802995334797 Epsilon spent :  0\n",
      "Epoch : 239 Loss D real :  0.010000322725634342 Loss D fake :  0.010012303982933035 Loss G :  0.010015498690388418 Epsilon spent :  0\n",
      "Epoch : 240 Loss D real :  0.01 Loss D fake :  0.010023722353716246 Loss G :  0.01002326936566272 Epsilon spent :  0\n",
      "Epoch : 241 Loss D real :  0.010000447043339973 Loss D fake :  0.01001442826677358 Loss G :  0.010015054940792632 Epsilon spent :  0\n",
      "Epoch : 242 Loss D real :  0.010001927192342244 Loss D fake :  0.010018824027125901 Loss G :  0.010019608333266199 Epsilon spent :  0\n",
      "Epoch : 243 Loss D real :  0.010000766144228724 Loss D fake :  0.010023849012375777 Loss G :  0.010026303919768387 Epsilon spent :  0\n",
      "Epoch : 244 Loss D real :  0.010000486285639317 Loss D fake :  0.010019015969948765 Loss G :  0.010010267759326863 Epsilon spent :  0\n",
      "Epoch : 245 Loss D real :  0.010000418434205906 Loss D fake :  0.010014062423305985 Loss G :  0.01001287106745446 Epsilon spent :  0\n",
      "Epoch : 246 Loss D real :  0.010001244205808116 Loss D fake :  0.010015812990010468 Loss G :  0.010014687015981318 Epsilon spent :  0\n",
      "Epoch : 247 Loss D real :  0.010001086576697576 Loss D fake :  0.010010513099172249 Loss G :  0.010017708171210078 Epsilon spent :  0\n",
      "Epoch : 248 Loss D real :  0.010001529107552407 Loss D fake :  0.010012433655846378 Loss G :  0.010004985249615118 Epsilon spent :  0\n",
      "Epoch : 249 Loss D real :  0.0100009205349985 Loss D fake :  0.010010380961565955 Loss G :  0.010013122974886043 Epsilon spent :  0\n",
      "Epoch : 250 Loss D real :  0.010001543954960517 Loss D fake :  0.010012426894261125 Loss G :  0.010007216376880231 Epsilon spent :  0\n",
      "Epoch : 251 Loss D real :  0.010001823635235867 Loss D fake :  0.010013257151943913 Loss G :  0.010014801855125467 Epsilon spent :  0\n",
      "Epoch : 252 Loss D real :  0.01 Loss D fake :  0.010011615982164103 Loss G :  0.01001474637356307 Epsilon spent :  0\n",
      "Epoch : 253 Loss D real :  0.010000825926655738 Loss D fake :  0.010016160740229079 Loss G :  0.010013688553987966 Epsilon spent :  0\n",
      "Epoch : 254 Loss D real :  0.010003021928942405 Loss D fake :  0.01001267644393852 Loss G :  0.010007428437298287 Epsilon spent :  0\n",
      "Epoch : 255 Loss D real :  0.01 Loss D fake :  0.01001525260077886 Loss G :  0.010008498902463569 Epsilon spent :  0\n",
      "Epoch : 256 Loss D real :  0.010002740225289217 Loss D fake :  0.010016996859861266 Loss G :  0.010011756833680933 Epsilon spent :  0\n",
      "Epoch : 257 Loss D real :  0.010001577078730377 Loss D fake :  0.01001258846502778 Loss G :  0.010012422394029464 Epsilon spent :  0\n",
      "Epoch : 258 Loss D real :  0.010000377176977373 Loss D fake :  0.010016040474162371 Loss G :  0.010008325831342951 Epsilon spent :  0\n",
      "Epoch : 259 Loss D real :  0.010000699663675835 Loss D fake :  0.010011292170954224 Loss G :  0.010012506323725823 Epsilon spent :  0\n",
      "Epoch : 260 Loss D real :  0.010002081476124022 Loss D fake :  0.01001659911546743 Loss G :  0.010012237299053556 Epsilon spent :  0\n",
      "Epoch : 261 Loss D real :  0.01 Loss D fake :  0.010014254677346181 Loss G :  0.010016070168695634 Epsilon spent :  0\n",
      "Epoch : 262 Loss D real :  0.010000989007253661 Loss D fake :  0.01001014354047233 Loss G :  0.010010239861153352 Epsilon spent :  0\n",
      "Epoch : 263 Loss D real :  0.01000151338803224 Loss D fake :  0.010015422544754142 Loss G :  0.010014934769897867 Epsilon spent :  0\n",
      "Epoch : 264 Loss D real :  0.010002456935221313 Loss D fake :  0.010016034158588438 Loss G :  0.0100150561021209 Epsilon spent :  0\n",
      "Epoch : 265 Loss D real :  0.01000101760237579 Loss D fake :  0.010010878324545634 Loss G :  0.010011405442242553 Epsilon spent :  0\n",
      "Epoch : 266 Loss D real :  0.010001948133835963 Loss D fake :  0.010010192606838332 Loss G :  0.010004712208459996 Epsilon spent :  0\n",
      "Epoch : 267 Loss D real :  0.010000045847225175 Loss D fake :  0.010013738729460517 Loss G :  0.010019567933900093 Epsilon spent :  0\n",
      "Epoch : 268 Loss D real :  0.010001528625757511 Loss D fake :  0.01001185298695673 Loss G :  0.01000915496780173 Epsilon spent :  0\n",
      "Epoch : 269 Loss D real :  0.010000565942000366 Loss D fake :  0.010017343518301785 Loss G :  0.010013185996259319 Epsilon spent :  0\n",
      "Epoch : 270 Loss D real :  0.010000264236193206 Loss D fake :  0.010006244736376482 Loss G :  0.010014683394736575 Epsilon spent :  0\n",
      "Epoch : 271 Loss D real :  0.010001322590035588 Loss D fake :  0.010014709150923905 Loss G :  0.010005735160813527 Epsilon spent :  0\n",
      "Epoch : 272 Loss D real :  0.01000000665783187 Loss D fake :  0.010007604602315916 Loss G :  0.010015617808640348 Epsilon spent :  0\n",
      "Epoch : 273 Loss D real :  0.010001093107918045 Loss D fake :  0.010012564160886202 Loss G :  0.010009517792084466 Epsilon spent :  0\n",
      "Epoch : 274 Loss D real :  0.010001598776055066 Loss D fake :  0.010007185516821327 Loss G :  0.010014460635804277 Epsilon spent :  0\n",
      "Epoch : 275 Loss D real :  0.010000828242083417 Loss D fake :  0.010010687658468223 Loss G :  0.01001400589819784 Epsilon spent :  0\n",
      "Epoch : 276 Loss D real :  0.010000690544367245 Loss D fake :  0.010003575058481535 Loss G :  0.010013372492466022 Epsilon spent :  0\n",
      "Epoch : 277 Loss D real :  0.010001127581062762 Loss D fake :  0.010009541401455836 Loss G :  0.010007408091889174 Epsilon spent :  0\n",
      "Epoch : 278 Loss D real :  0.01 Loss D fake :  0.01001390270539497 Loss G :  0.010017016483703314 Epsilon spent :  0\n",
      "Epoch : 279 Loss D real :  0.010001146978015777 Loss D fake :  0.010006202959491171 Loss G :  0.010011911640015289 Epsilon spent :  0\n",
      "Epoch : 280 Loss D real :  0.010001349925743213 Loss D fake :  0.010008445513689426 Loss G :  0.01000890562641348 Epsilon spent :  0\n",
      "Epoch : 281 Loss D real :  0.010000381048671028 Loss D fake :  0.01000970441302182 Loss G :  0.010008852246465846 Epsilon spent :  0\n",
      "Epoch : 282 Loss D real :  0.010000289260504548 Loss D fake :  0.0100091889338349 Loss G :  0.010010741382392377 Epsilon spent :  0\n",
      "Epoch : 283 Loss D real :  0.01000126337503475 Loss D fake :  0.010007670035399758 Loss G :  0.010013838657099424 Epsilon spent :  0\n",
      "Epoch : 284 Loss D real :  0.010001772061088115 Loss D fake :  0.01001059553419353 Loss G :  0.010012775412292254 Epsilon spent :  0\n",
      "Epoch : 285 Loss D real :  0.010000875679476523 Loss D fake :  0.01000544392839453 Loss G :  0.01001357562531656 Epsilon spent :  0\n",
      "Epoch : 286 Loss D real :  0.010000660751730986 Loss D fake :  0.010007705477607293 Loss G :  0.010009017275703608 Epsilon spent :  0\n",
      "Epoch : 287 Loss D real :  0.010000815533090112 Loss D fake :  0.010009914132004935 Loss G :  0.010009425823173214 Epsilon spent :  0\n",
      "Epoch : 288 Loss D real :  0.010000466343674963 Loss D fake :  0.010009806752195777 Loss G :  0.010006714429572156 Epsilon spent :  0\n",
      "Epoch : 289 Loss D real :  0.010002023662888585 Loss D fake :  0.010008435171762985 Loss G :  0.010011505597671968 Epsilon spent :  0\n",
      "Epoch : 290 Loss D real :  0.010000321540043502 Loss D fake :  0.01000597321738121 Loss G :  0.010007570166888455 Epsilon spent :  0\n",
      "Epoch : 291 Loss D real :  0.010001494864901712 Loss D fake :  0.010006594921908434 Loss G :  0.010013337846837334 Epsilon spent :  0\n",
      "Epoch : 292 Loss D real :  0.010000370529820318 Loss D fake :  0.010009617091620846 Loss G :  0.010015250498993537 Epsilon spent :  0\n",
      "Epoch : 293 Loss D real :  0.01 Loss D fake :  0.010008291960150142 Loss G :  0.010008645918549207 Epsilon spent :  0\n",
      "Epoch : 294 Loss D real :  0.010001810257557439 Loss D fake :  0.01000323427874064 Loss G :  0.010006980365189924 Epsilon spent :  0\n",
      "Epoch : 295 Loss D real :  0.01 Loss D fake :  0.01001089010419902 Loss G :  0.010006768534489677 Epsilon spent :  0\n",
      "Epoch : 296 Loss D real :  0.010000442265922591 Loss D fake :  0.010007513485750137 Loss G :  0.01000644850350609 Epsilon spent :  0\n",
      "Epoch : 297 Loss D real :  0.010001285929025274 Loss D fake :  0.010008493224210716 Loss G :  0.01000653609234778 Epsilon spent :  0\n",
      "Epoch : 298 Loss D real :  0.010000418197465652 Loss D fake :  0.0100077040655198 Loss G :  0.01000755849476437 Epsilon spent :  0\n",
      "Epoch : 299 Loss D real :  0.010000993429469071 Loss D fake :  0.010006570300707243 Loss G :  0.0100056021409647 Epsilon spent :  0\n",
      "Epoch : 300 Loss D real :  0.010001907227533304 Loss D fake :  0.010003362626297176 Loss G :  0.010006441434742303 Epsilon spent :  0\n",
      "Epoch : 301 Loss D real :  0.010000289002495213 Loss D fake :  0.01000358579526714 Loss G :  0.010009731790274359 Epsilon spent :  0\n",
      "Epoch : 302 Loss D real :  0.010000973774080709 Loss D fake :  0.010009017633680697 Loss G :  0.010006155980086555 Epsilon spent :  0\n",
      "Epoch : 303 Loss D real :  0.010002375425188609 Loss D fake :  0.010005802795678694 Loss G :  0.01000429724095508 Epsilon spent :  0\n",
      "Epoch : 304 Loss D real :  0.010001312299542545 Loss D fake :  0.0100076631433688 Loss G :  0.010013003736628908 Epsilon spent :  0\n",
      "Epoch : 305 Loss D real :  0.010001369221422498 Loss D fake :  0.010007896802321378 Loss G :  0.010004928448709394 Epsilon spent :  0\n",
      "Epoch : 306 Loss D real :  0.010001151070596483 Loss D fake :  0.010008941266178246 Loss G :  0.010008436390269786 Epsilon spent :  0\n",
      "Epoch : 307 Loss D real :  0.010000039049419313 Loss D fake :  0.0100073804636426 Loss G :  0.010006680476214395 Epsilon spent :  0\n",
      "Epoch : 308 Loss D real :  0.01000263709589358 Loss D fake :  0.0100066129785968 Loss G :  0.01000892685113743 Epsilon spent :  0\n",
      "Epoch : 309 Loss D real :  0.010000006756434162 Loss D fake :  0.010002261157428546 Loss G :  0.010012845803942176 Epsilon spent :  0\n",
      "Epoch : 310 Loss D real :  0.010000129431821438 Loss D fake :  0.010005674080964571 Loss G :  0.010003602503756 Epsilon spent :  0\n",
      "Epoch : 311 Loss D real :  0.010000268112939262 Loss D fake :  0.01000512070290855 Loss G :  0.010002295158857873 Epsilon spent :  0\n",
      "Epoch : 312 Loss D real :  0.01 Loss D fake :  0.010005892601330325 Loss G :  0.010006331648578282 Epsilon spent :  0\n",
      "Epoch : 313 Loss D real :  0.010000645154625409 Loss D fake :  0.01000585751355185 Loss G :  0.010006411712165094 Epsilon spent :  0\n",
      "Epoch : 314 Loss D real :  0.010000107217837529 Loss D fake :  0.010005837340654826 Loss G :  0.010005858236136325 Epsilon spent :  0\n",
      "Epoch : 315 Loss D real :  0.010000829219691868 Loss D fake :  0.01000361067945945 Loss G :  0.010006832814782839 Epsilon spent :  0\n",
      "Epoch : 316 Loss D real :  0.01000190287052268 Loss D fake :  0.010004640473096904 Loss G :  0.01000657985694433 Epsilon spent :  0\n",
      "Epoch : 317 Loss D real :  0.010001353541024608 Loss D fake :  0.010004646084420251 Loss G :  0.010003745358112362 Epsilon spent :  0\n",
      "Epoch : 318 Loss D real :  0.010000335010442368 Loss D fake :  0.010004723235905733 Loss G :  0.01000757367923133 Epsilon spent :  0\n",
      "Epoch : 319 Loss D real :  0.010000265568541037 Loss D fake :  0.010003116132991399 Loss G :  0.010007270050544994 Epsilon spent :  0\n",
      "Epoch : 320 Loss D real :  0.010000455026820915 Loss D fake :  0.010005086366899733 Loss G :  0.01000657090966453 Epsilon spent :  0\n",
      "Epoch : 321 Loss D real :  0.010000784909809364 Loss D fake :  0.01000641816860011 Loss G :  0.010006495514703248 Epsilon spent :  0\n",
      "Epoch : 322 Loss D real :  0.01000327136974451 Loss D fake :  0.010000872585377435 Loss G :  0.01000511649573469 Epsilon spent :  0\n",
      "Epoch : 323 Loss D real :  0.010000036811724337 Loss D fake :  0.010004915693803587 Loss G :  0.010004999507549624 Epsilon spent :  0\n",
      "Epoch : 324 Loss D real :  0.01 Loss D fake :  0.010002444225163862 Loss G :  0.010004246718584485 Epsilon spent :  0\n",
      "Epoch : 325 Loss D real :  0.010000425555743625 Loss D fake :  0.010005635253117815 Loss G :  0.010003509821715405 Epsilon spent :  0\n",
      "Epoch : 326 Loss D real :  0.010002089467376848 Loss D fake :  0.01000499229570304 Loss G :  0.010005144132808865 Epsilon spent :  0\n",
      "Epoch : 327 Loss D real :  0.010000079127235814 Loss D fake :  0.010004262513555559 Loss G :  0.010007702187836875 Epsilon spent :  0\n",
      "Epoch : 328 Loss D real :  0.01000040708674446 Loss D fake :  0.01000584761996151 Loss G :  0.010007734906281197 Epsilon spent :  0\n",
      "Epoch : 329 Loss D real :  0.010000893847112481 Loss D fake :  0.010005210986976206 Loss G :  0.010003770863850339 Epsilon spent :  0\n",
      "Epoch : 330 Loss D real :  0.010000807887794436 Loss D fake :  0.01000576986465512 Loss G :  0.010005800453982338 Epsilon spent :  0\n",
      "Epoch : 331 Loss D real :  0.01000077198827964 Loss D fake :  0.010004728507115512 Loss G :  0.010002276622812011 Epsilon spent :  0\n",
      "Epoch : 332 Loss D real :  0.010000528086310955 Loss D fake :  0.010006016963840195 Loss G :  0.010003790170157425 Epsilon spent :  0\n",
      "Epoch : 333 Loss D real :  0.010000437092950032 Loss D fake :  0.01000206334115378 Loss G :  0.010001927139516448 Epsilon spent :  0\n",
      "Epoch : 334 Loss D real :  0.010000365118773051 Loss D fake :  0.010004414591657147 Loss G :  0.01000183532157804 Epsilon spent :  0\n",
      "Epoch : 335 Loss D real :  0.010000218705086541 Loss D fake :  0.010004162334221476 Loss G :  0.01000466028087451 Epsilon spent :  0\n",
      "Epoch : 336 Loss D real :  0.010000216457550734 Loss D fake :  0.010003707845500672 Loss G :  0.01000597394234182 Epsilon spent :  0\n",
      "Epoch : 337 Loss D real :  0.010000360067248372 Loss D fake :  0.010003651743637255 Loss G :  0.010003195208611457 Epsilon spent :  0\n",
      "Epoch : 338 Loss D real :  0.01 Loss D fake :  0.01000489216440835 Loss G :  0.010005288485343844 Epsilon spent :  0\n",
      "Epoch : 339 Loss D real :  0.01 Loss D fake :  0.010005486914133308 Loss G :  0.01000453824463114 Epsilon spent :  0\n",
      "Epoch : 340 Loss D real :  0.010000427622241159 Loss D fake :  0.010001948612460513 Loss G :  0.010000926741624967 Epsilon spent :  0\n",
      "Epoch : 341 Loss D real :  0.01 Loss D fake :  0.010004265681056404 Loss G :  0.010003691628456761 Epsilon spent :  0\n",
      "Epoch : 342 Loss D real :  0.01000025738953153 Loss D fake :  0.01000323056630717 Loss G :  0.010002791931490914 Epsilon spent :  0\n",
      "Epoch : 343 Loss D real :  0.010001176971499716 Loss D fake :  0.010002647675208389 Loss G :  0.010000979208959712 Epsilon spent :  0\n",
      "Epoch : 344 Loss D real :  0.010001115401477037 Loss D fake :  0.010003111487545603 Loss G :  0.010002871695335175 Epsilon spent :  0\n",
      "Epoch : 345 Loss D real :  0.010000646442254282 Loss D fake :  0.010002558240421875 Loss G :  0.0100047604414918 Epsilon spent :  0\n",
      "Epoch : 346 Loss D real :  0.01 Loss D fake :  0.01000158946370076 Loss G :  0.010003724856157201 Epsilon spent :  0\n",
      "Epoch : 347 Loss D real :  0.01 Loss D fake :  0.010002873625271606 Loss G :  0.010003420996234705 Epsilon spent :  0\n",
      "Epoch : 348 Loss D real :  0.01 Loss D fake :  0.01000344038243138 Loss G :  0.010002813393918585 Epsilon spent :  0\n",
      "Epoch : 349 Loss D real :  0.010000732224702371 Loss D fake :  0.010001696042142983 Loss G :  0.010003004196449342 Epsilon spent :  0\n",
      "Epoch : 350 Loss D real :  0.01 Loss D fake :  0.010001523483364118 Loss G :  0.010001423526305037 Epsilon spent :  0\n",
      "Epoch : 351 Loss D real :  0.01000065750109833 Loss D fake :  0.010002733528517268 Loss G :  0.01000289585931722 Epsilon spent :  0\n",
      "Epoch : 352 Loss D real :  0.01 Loss D fake :  0.010004213304403379 Loss G :  0.010002093771767336 Epsilon spent :  0\n",
      "Epoch : 353 Loss D real :  0.01 Loss D fake :  0.010003167357865873 Loss G :  0.010004004053645281 Epsilon spent :  0\n",
      "Epoch : 354 Loss D real :  0.01 Loss D fake :  0.010003575547295229 Loss G :  0.010000578713566547 Epsilon spent :  0\n",
      "Epoch : 355 Loss D real :  0.010000952864315875 Loss D fake :  0.010001114375204314 Loss G :  0.010001374355257522 Epsilon spent :  0\n",
      "Epoch : 356 Loss D real :  0.01 Loss D fake :  0.010003986337235858 Loss G :  0.010007066229437155 Epsilon spent :  0\n",
      "Epoch : 357 Loss D real :  0.010000823801926068 Loss D fake :  0.01000248217884997 Loss G :  0.010002623473316125 Epsilon spent :  0\n",
      "Epoch : 358 Loss D real :  0.01 Loss D fake :  0.010002911216610321 Loss G :  0.010002523695131346 Epsilon spent :  0\n",
      "Epoch : 359 Loss D real :  0.01 Loss D fake :  0.010003221057724474 Loss G :  0.010003399805738188 Epsilon spent :  0\n",
      "Epoch : 360 Loss D real :  0.01 Loss D fake :  0.010001201443688563 Loss G :  0.010001302420090067 Epsilon spent :  0\n",
      "Epoch : 361 Loss D real :  0.01 Loss D fake :  0.010002239520822064 Loss G :  0.01000391162189495 Epsilon spent :  0\n",
      "Epoch : 362 Loss D real :  0.010000875568508394 Loss D fake :  0.010001530626458775 Loss G :  0.010001631251202157 Epsilon spent :  0\n",
      "Epoch : 363 Loss D real :  0.01000010857670767 Loss D fake :  0.010001448656999264 Loss G :  0.01000360587617173 Epsilon spent :  0\n",
      "Epoch : 364 Loss D real :  0.010001671576657399 Loss D fake :  0.010000958154384145 Loss G :  0.010001934303719952 Epsilon spent :  0\n",
      "Epoch : 365 Loss D real :  0.010000082063648157 Loss D fake :  0.010000952437491599 Loss G :  0.01000360027599798 Epsilon spent :  0\n",
      "Epoch : 366 Loss D real :  0.010000771903170618 Loss D fake :  0.010002127804283193 Loss G :  0.010002385280851026 Epsilon spent :  0\n",
      "Epoch : 367 Loss D real :  0.010000797641752624 Loss D fake :  0.010001335426175796 Loss G :  0.010001549761517558 Epsilon spent :  0\n",
      "Epoch : 368 Loss D real :  0.01 Loss D fake :  0.010001902046887366 Loss G :  0.010001634134453393 Epsilon spent :  0\n",
      "Epoch : 369 Loss D real :  0.010000219429173231 Loss D fake :  0.010001216876126357 Loss G :  0.010002222948842622 Epsilon spent :  0\n",
      "Epoch : 370 Loss D real :  0.010001457542383104 Loss D fake :  0.01000215342995116 Loss G :  0.010001083753136792 Epsilon spent :  0\n",
      "Epoch : 371 Loss D real :  0.0100005215923727 Loss D fake :  0.010002136615837605 Loss G :  0.010002227607449753 Epsilon spent :  0\n",
      "Epoch : 372 Loss D real :  0.01 Loss D fake :  0.010001195750486691 Loss G :  0.010000867966455707 Epsilon spent :  0\n",
      "Epoch : 373 Loss D real :  0.010000356703435135 Loss D fake :  0.01000122906242447 Loss G :  0.01000053028120984 Epsilon spent :  0\n",
      "Epoch : 374 Loss D real :  0.010000390167997213 Loss D fake :  0.010001439679778392 Loss G :  0.010001109520360126 Epsilon spent :  0\n",
      "Epoch : 375 Loss D real :  0.010000267465970413 Loss D fake :  0.01000177549617232 Loss G :  0.010001192408342838 Epsilon spent :  0\n",
      "Epoch : 376 Loss D real :  0.010000215956006697 Loss D fake :  0.01000142510628893 Loss G :  0.01000083706571318 Epsilon spent :  0\n",
      "Epoch : 377 Loss D real :  0.010000119534647588 Loss D fake :  0.010001132337102545 Loss G :  0.010002436834674317 Epsilon spent :  0\n",
      "Epoch : 378 Loss D real :  0.010000261345253076 Loss D fake :  0.010000348702326755 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 379 Loss D real :  0.010000450756527316 Loss D fake :  0.010001325376638056 Loss G :  0.010000763308969103 Epsilon spent :  0\n",
      "Epoch : 380 Loss D real :  0.010000047548579853 Loss D fake :  0.0100003792896453 Loss G :  0.010001409750568263 Epsilon spent :  0\n",
      "Epoch : 381 Loss D real :  0.010000132395331226 Loss D fake :  0.010001396322955198 Loss G :  0.010000756531058135 Epsilon spent :  0\n",
      "Epoch : 382 Loss D real :  0.010001349348035916 Loss D fake :  0.010001288628716753 Loss G :  0.010000398972524088 Epsilon spent :  0\n",
      "Epoch : 383 Loss D real :  0.01 Loss D fake :  0.010000731526283864 Loss G :  0.010001494021342355 Epsilon spent :  0\n",
      "Epoch : 384 Loss D real :  0.01000141631742402 Loss D fake :  0.01000107197343229 Loss G :  0.010000916763297809 Epsilon spent :  0\n",
      "Epoch : 385 Loss D real :  0.010001763366772906 Loss D fake :  0.010001045202043013 Loss G :  0.010000240593983812 Epsilon spent :  0\n",
      "Epoch : 386 Loss D real :  0.010000712186907994 Loss D fake :  0.010000808279847066 Loss G :  0.01000091585865993 Epsilon spent :  0\n",
      "Epoch : 387 Loss D real :  0.010000203130361604 Loss D fake :  0.010000570047781397 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 388 Loss D real :  0.01 Loss D fake :  0.01000094729772958 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 389 Loss D real :  0.01 Loss D fake :  0.010000419065751944 Loss G :  0.010000232726770468 Epsilon spent :  0\n",
      "Epoch : 390 Loss D real :  0.01000062359194023 Loss D fake :  0.010000399862574323 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 391 Loss D real :  0.01 Loss D fake :  0.010001241946717518 Loss G :  0.010000946136411138 Epsilon spent :  0\n",
      "Epoch : 392 Loss D real :  0.010000654083450026 Loss D fake :  0.010001168882671066 Loss G :  0.010000185158971008 Epsilon spent :  0\n",
      "Epoch : 393 Loss D real :  0.010000639417431421 Loss D fake :  0.010000434244166696 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 394 Loss D real :  0.01000098008551049 Loss D fake :  0.010001933113143983 Loss G :  0.010000506788370053 Epsilon spent :  0\n",
      "Epoch : 395 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.010000361218398457 Epsilon spent :  0\n",
      "Epoch : 396 Loss D real :  0.01 Loss D fake :  0.010000143238428589 Loss G :  0.010000312051437574 Epsilon spent :  0\n",
      "Epoch : 397 Loss D real :  0.01 Loss D fake :  0.010000188860336774 Loss G :  0.01000080751847525 Epsilon spent :  0\n",
      "Epoch : 398 Loss D real :  0.010000666085234066 Loss D fake :  0.010000328293593692 Loss G :  0.010000050032930778 Epsilon spent :  0\n",
      "Epoch : 399 Loss D real :  0.010000168963226213 Loss D fake :  0.010000314182646812 Loss G :  0.010000553793200672 Epsilon spent :  0\n",
      "Epoch : 400 Loss D real :  0.010000454650696466 Loss D fake :  0.010000178182975907 Loss G :  0.010000279426758331 Epsilon spent :  0\n",
      "Epoch : 401 Loss D real :  0.010000359445008046 Loss D fake :  0.01 Loss G :  0.010000301540755666 Epsilon spent :  0\n",
      "Epoch : 402 Loss D real :  0.010001324114712617 Loss D fake :  0.010000335800249 Loss G :  0.010000005844378674 Epsilon spent :  0\n",
      "Epoch : 403 Loss D real :  0.010000140434568336 Loss D fake :  0.01000061799106157 Loss G :  0.01000050242518052 Epsilon spent :  0\n",
      "Epoch : 404 Loss D real :  0.01 Loss D fake :  0.0100004044622928 Loss G :  0.010000174603609066 Epsilon spent :  0\n",
      "Epoch : 405 Loss D real :  0.01 Loss D fake :  0.010000209864755439 Loss G :  0.010000385620162538 Epsilon spent :  0\n",
      "Epoch : 406 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.010000541727999187 Epsilon spent :  0\n",
      "Epoch : 407 Loss D real :  0.010000617591724863 Loss D fake :  0.01000028681227956 Loss G :  0.01000020435740346 Epsilon spent :  0\n",
      "Epoch : 408 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 409 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 410 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 411 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 412 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 413 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 414 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 415 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 416 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 417 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 418 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 419 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 420 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 421 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 422 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 423 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 424 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 425 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 426 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 427 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 428 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 429 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 430 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 431 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 432 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 433 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 434 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 435 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 436 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 437 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 438 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 439 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 440 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 441 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 442 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 443 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 444 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 445 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 446 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 447 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 448 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 449 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 450 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 451 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 452 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 453 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 454 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 455 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 456 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 457 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 458 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 459 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 460 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 461 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 462 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 463 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 464 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 465 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 466 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 467 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 468 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 469 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 470 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 471 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 472 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 473 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 474 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 475 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 476 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 477 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 478 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 479 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 480 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 481 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 482 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 483 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 484 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 485 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 486 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 487 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 488 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 489 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 490 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 491 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 492 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 493 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 494 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 495 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 496 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 497 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 498 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 499 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 500 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
      "Epoch : 501 Loss D real :  0.01 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  inf\n",
      "AUC scores of downstream classifiers on test data : \n",
      "----------------------------------------\n",
      "LR: 0.3038312216178449\n",
      "----------------------------------------\n",
      "Random Forest: 0.32610482340256874\n",
      "----------------------------------------\n",
      "Neural Network: 0.2576421853777834\n",
      "----------------------------------------\n",
      "GaussianNB: 0.45289596950843314\n",
      "----------------------------------------\n",
      "GradientBoostingClassifier: 0.3266898948235702\n",
      "Saved synthetic data at :  /home/ec2-user/studies/GRAIMatter/data/Synthetic_generation/Synthetic/\n",
      "Processing differential privacy level 1\n",
      "Epoch : 1 Loss D real :  0.0100073430218751 Loss D fake :  0.01000428211339376 Loss G :  0.010066385555741776 Epsilon spent :  2.4445776245973785\n",
      "AUC scores of downstream classifiers on test data : \n",
      "----------------------------------------\n",
      "LR: 0.7344876758329856\n",
      "----------------------------------------\n",
      "Random Forest: 0.4630847098521442\n",
      "----------------------------------------\n",
      "Neural Network: 0.7480503387065033\n",
      "----------------------------------------\n",
      "GaussianNB: 0.39383444183110233\n",
      "----------------------------------------\n",
      "GradientBoostingClassifier: 0.4423956498275532\n",
      "Saved synthetic data at :  /home/ec2-user/studies/GRAIMatter/data/Synthetic_generation/Synthetic/\n",
      "Processing differential privacy level 2\n",
      "Epoch : 1 Loss D real :  0.01004079019851293 Loss D fake :  0.010100301797235825 Loss G :  0.010138684103114436 Epsilon spent :  2.4445776245973785\n",
      "AUC scores of downstream classifiers on test data : \n",
      "----------------------------------------\n",
      "LR: 0.8642299039429069\n",
      "----------------------------------------\n",
      "Random Forest: 0.5914369332495681\n",
      "----------------------------------------\n",
      "Neural Network: 0.7856612213229888\n",
      "----------------------------------------\n",
      "GaussianNB: 0.5877919791045008\n",
      "----------------------------------------\n",
      "GradientBoostingClassifier: 0.5881636698892937\n",
      "Saved synthetic data at :  /home/ec2-user/studies/GRAIMatter/data/Synthetic_generation/Synthetic/\n",
      "Processing differential privacy level 4\n",
      "Epoch : 1 Loss D real :  0.010238720629303984 Loss D fake :  0.010259092338806257 Loss G :  0.01032262488359073 Epsilon spent :  2.4445776245973785\n",
      "Epoch : 2 Loss D real :  0.010351010431363656 Loss D fake :  0.01053212191234815 Loss G :  0.01062393065230407 Epsilon spent :  2.5865701562007106\n",
      "Epoch : 3 Loss D real :  0.010247196285544019 Loss D fake :  0.010597520020444675 Loss G :  0.010593848752187295 Epsilon spent :  2.728562687804043\n",
      "Epoch : 4 Loss D real :  0.010184751273340566 Loss D fake :  0.010606371948500254 Loss G :  0.01065231192699783 Epsilon spent :  2.870555219407376\n",
      "Epoch : 5 Loss D real :  0.010110774714916183 Loss D fake :  0.010639359874674416 Loss G :  0.010680250471254482 Epsilon spent :  3.012547751010708\n",
      "Epoch : 6 Loss D real :  0.010134265769816447 Loss D fake :  0.010672218550585437 Loss G :  0.010724276868216765 Epsilon spent :  3.1545402826140405\n",
      "Epoch : 7 Loss D real :  0.010100875085681497 Loss D fake :  0.010760241581818868 Loss G :  0.010713815790847146 Epsilon spent :  3.296532814217373\n",
      "Epoch : 8 Loss D real :  0.010083469023328347 Loss D fake :  0.01068679415966461 Loss G :  0.01078811459904801 Epsilon spent :  3.4385253458207057\n",
      "Epoch : 9 Loss D real :  0.010080498720854023 Loss D fake :  0.010659299586490312 Loss G :  0.010766160581806947 Epsilon spent :  3.5689661548234306\n",
      "Epoch : 10 Loss D real :  0.010054092538730651 Loss D fake :  0.010630026175380091 Loss G :  0.010717381515177378 Epsilon spent :  3.6457144646657498\n",
      "Epoch : 11 Loss D real :  0.010051037172392948 Loss D fake :  0.010648249929806146 Loss G :  0.010702713759179843 Epsilon spent :  3.7224627745080694\n",
      "Epoch : 12 Loss D real :  0.010062087727758701 Loss D fake :  0.01079610677338364 Loss G :  0.010697658840398439 Epsilon spent :  3.7992110843503886\n",
      "Epoch : 13 Loss D real :  0.010080206259018483 Loss D fake :  0.010716178480478454 Loss G :  0.010807135073117292 Epsilon spent :  3.8759593941927077\n",
      "Epoch : 14 Loss D real :  0.010101187311781262 Loss D fake :  0.010770726080240604 Loss G :  0.010836835693510141 Epsilon spent :  3.952707704035027\n",
      "Epoch : 15 Loss D real :  0.010076612692289284 Loss D fake :  0.010659944407538719 Loss G :  0.010759932157723837 Epsilon spent :  4.029456013877346\n",
      "AUC scores of downstream classifiers on test data : \n",
      "----------------------------------------\n",
      "LR: 0.4713743085233152\n",
      "----------------------------------------\n",
      "Random Forest: 0.23277502967665165\n",
      "----------------------------------------\n",
      "Neural Network: 0.9233589644811957\n",
      "----------------------------------------\n",
      "GaussianNB: 0.5379426057898467\n",
      "----------------------------------------\n",
      "GradientBoostingClassifier: 0.3667465832193083\n",
      "Saved synthetic data at :  /home/ec2-user/studies/GRAIMatter/data/Synthetic_generation/Synthetic/\n",
      "Processing differential privacy level 8\n",
      "Epoch : 1 Loss D real :  0.009963357148270255 Loss D fake :  0.009979694523210373 Loss G :  0.010035447172388974 Epsilon spent :  2.4445776245973785\n",
      "Epoch : 2 Loss D real :  0.010152636548846676 Loss D fake :  0.010089446432381351 Loss G :  0.010148885288925578 Epsilon spent :  2.5865701562007106\n",
      "Epoch : 3 Loss D real :  0.010318563103689156 Loss D fake :  0.010250039035315416 Loss G :  0.010331954262964953 Epsilon spent :  2.728562687804043\n",
      "Epoch : 4 Loss D real :  0.01036228603008389 Loss D fake :  0.010282505941611859 Loss G :  0.010374697241036075 Epsilon spent :  2.870555219407376\n",
      "Epoch : 5 Loss D real :  0.010333834426154317 Loss D fake :  0.010321061273172644 Loss G :  0.010365620776522602 Epsilon spent :  3.012547751010708\n",
      "Epoch : 6 Loss D real :  0.010323136855342084 Loss D fake :  0.01033123411112591 Loss G :  0.010384589371679697 Epsilon spent :  3.1545402826140405\n",
      "Epoch : 7 Loss D real :  0.010280618535229642 Loss D fake :  0.01033049284509915 Loss G :  0.0104016430770341 Epsilon spent :  3.296532814217373\n",
      "Epoch : 8 Loss D real :  0.010200053797856799 Loss D fake :  0.010341833571769737 Loss G :  0.010373300250853555 Epsilon spent :  3.4385253458207057\n",
      "Epoch : 9 Loss D real :  0.010210510694798688 Loss D fake :  0.010357263528158705 Loss G :  0.01040452371266176 Epsilon spent :  3.5689661548234306\n",
      "Epoch : 10 Loss D real :  0.010212407356610087 Loss D fake :  0.010359568820187966 Loss G :  0.010449463917688372 Epsilon spent :  3.6457144646657498\n",
      "Epoch : 11 Loss D real :  0.010147491991714414 Loss D fake :  0.01037074523838173 Loss G :  0.01042503353440806 Epsilon spent :  3.7224627745080694\n",
      "Epoch : 12 Loss D real :  0.010167966478509169 Loss D fake :  0.010377058293354217 Loss G :  0.010439163276082256 Epsilon spent :  3.7992110843503886\n",
      "Epoch : 13 Loss D real :  0.010127593786991495 Loss D fake :  0.010379296861643378 Loss G :  0.010465820980834574 Epsilon spent :  3.8759593941927077\n",
      "Epoch : 14 Loss D real :  0.010155337603957995 Loss D fake :  0.01038222562614712 Loss G :  0.010433435479869572 Epsilon spent :  3.952707704035027\n",
      "Epoch : 15 Loss D real :  0.010108731528543243 Loss D fake :  0.010374226058567812 Loss G :  0.010425812847947868 Epsilon spent :  4.029456013877346\n",
      "Epoch : 16 Loss D real :  0.010140579178855592 Loss D fake :  0.010397271998172797 Loss G :  0.0104218803738797 Epsilon spent :  4.106204323719665\n",
      "Epoch : 17 Loss D real :  0.010124731004243562 Loss D fake :  0.010398571791847853 Loss G :  0.010423410984454958 Epsilon spent :  4.182952633561985\n",
      "Epoch : 18 Loss D real :  0.01011606938033134 Loss D fake :  0.010380082393420403 Loss G :  0.010456836480822924 Epsilon spent :  4.2597009434043045\n",
      "Epoch : 19 Loss D real :  0.010131660521514499 Loss D fake :  0.010388732023487274 Loss G :  0.010445526470624099 Epsilon spent :  4.336449253246624\n",
      "Epoch : 20 Loss D real :  0.010111926762058698 Loss D fake :  0.010354302246943788 Loss G :  0.01042506371142243 Epsilon spent :  4.413197563088943\n",
      "Epoch : 21 Loss D real :  0.010129350248959907 Loss D fake :  0.010383277370552694 Loss G :  0.010430785450614181 Epsilon spent :  4.489945872931262\n",
      "Epoch : 22 Loss D real :  0.010145502230399193 Loss D fake :  0.010396405257226175 Loss G :  0.01045471329247296 Epsilon spent :  4.566694182773581\n",
      "Epoch : 23 Loss D real :  0.010086554882866982 Loss D fake :  0.010376852610197558 Loss G :  0.010431277139050113 Epsilon spent :  4.6434424926159\n",
      "Epoch : 24 Loss D real :  0.010075197772014672 Loss D fake :  0.010395793175245471 Loss G :  0.010432894389483457 Epsilon spent :  4.7201908024582195\n",
      "Epoch : 25 Loss D real :  0.01008472868932793 Loss D fake :  0.010370919096502576 Loss G :  0.010449064651199607 Epsilon spent :  4.796939112300539\n",
      "Epoch : 26 Loss D real :  0.010132657861270253 Loss D fake :  0.010365015523685359 Loss G :  0.010463601983920238 Epsilon spent :  4.873687422142858\n",
      "Epoch : 27 Loss D real :  0.010155959133738523 Loss D fake :  0.010398388326797285 Loss G :  0.010427569388972574 Epsilon spent :  4.950435731985177\n",
      "Epoch : 28 Loss D real :  0.010118602379469134 Loss D fake :  0.01032250629381431 Loss G :  0.010399539845328026 Epsilon spent :  5.027184041827496\n",
      "Epoch : 29 Loss D real :  0.010104904891799538 Loss D fake :  0.010351048502018834 Loss G :  0.010420676133996214 Epsilon spent :  5.103932351669816\n",
      "Epoch : 30 Loss D real :  0.01008442917289579 Loss D fake :  0.010339171291770035 Loss G :  0.010391821873452667 Epsilon spent :  5.1806806615121355\n",
      "Epoch : 31 Loss D real :  0.010104670541690413 Loss D fake :  0.010370764781407308 Loss G :  0.010457508354691999 Epsilon spent :  5.257428971354455\n",
      "Epoch : 32 Loss D real :  0.010071200072667397 Loss D fake :  0.010388763670192579 Loss G :  0.010415578345884599 Epsilon spent :  5.334177281196774\n",
      "Epoch : 33 Loss D real :  0.010131351777111872 Loss D fake :  0.010345840093322322 Loss G :  0.010422975124976449 Epsilon spent :  5.410925591039094\n",
      "Epoch : 34 Loss D real :  0.010131968778864358 Loss D fake :  0.010380013464696814 Loss G :  0.010378107861376669 Epsilon spent :  5.487673900881413\n",
      "Epoch : 35 Loss D real :  0.010089096520809124 Loss D fake :  0.01037934048403394 Loss G :  0.01045099837623446 Epsilon spent :  5.564422210723732\n",
      "Epoch : 36 Loss D real :  0.01005616133137276 Loss D fake :  0.010378662664120885 Loss G :  0.010409270527392912 Epsilon spent :  5.641170520566051\n",
      "Epoch : 37 Loss D real :  0.010068008355188646 Loss D fake :  0.010340270246568814 Loss G :  0.01042428453360622 Epsilon spent :  5.717918830408371\n",
      "Epoch : 38 Loss D real :  0.010103209277381679 Loss D fake :  0.010383756457813267 Loss G :  0.010401709345413327 Epsilon spent :  5.79466714025069\n",
      "Epoch : 39 Loss D real :  0.01012326804152694 Loss D fake :  0.010362131914120758 Loss G :  0.010438498577817703 Epsilon spent :  5.871415450093009\n",
      "Epoch : 40 Loss D real :  0.010084189473507024 Loss D fake :  0.010372307129438494 Loss G :  0.010382925386426725 Epsilon spent :  5.948163759935328\n",
      "Epoch : 41 Loss D real :  0.010099353048250595 Loss D fake :  0.010356051433563562 Loss G :  0.010405595765674652 Epsilon spent :  6.024912069777647\n",
      "Epoch : 42 Loss D real :  0.010124230602306621 Loss D fake :  0.010363585811284985 Loss G :  0.010410868185915884 Epsilon spent :  6.101660379619966\n",
      "Epoch : 43 Loss D real :  0.01009767134627727 Loss D fake :  0.010330325600217951 Loss G :  0.010398473721688535 Epsilon spent :  6.178408689462286\n",
      "Epoch : 44 Loss D real :  0.010118552775359165 Loss D fake :  0.010317347341774958 Loss G :  0.010384897991378633 Epsilon spent :  6.246664086363785\n",
      "Epoch : 45 Loss D real :  0.010077912382283874 Loss D fake :  0.010375622034546452 Loss G :  0.010405356139461718 Epsilon spent :  6.301414592379855\n",
      "Epoch : 46 Loss D real :  0.010063954678062233 Loss D fake :  0.010324131872830707 Loss G :  0.010399226890548433 Epsilon spent :  6.356165098395923\n",
      "Epoch : 47 Loss D real :  0.010059608565366952 Loss D fake :  0.010338776237176772 Loss G :  0.010377973683803223 Epsilon spent :  6.410915604411993\n",
      "Epoch : 48 Loss D real :  0.010047850706199249 Loss D fake :  0.01032471181863755 Loss G :  0.010379355691417878 Epsilon spent :  6.465666110428062\n",
      "Epoch : 49 Loss D real :  0.010073887550814474 Loss D fake :  0.010340404196508318 Loss G :  0.010374920312650141 Epsilon spent :  6.52041661644413\n",
      "Epoch : 50 Loss D real :  0.01011581948849504 Loss D fake :  0.010306045068357314 Loss G :  0.010390794701618196 Epsilon spent :  6.5751671224602\n",
      "Epoch : 51 Loss D real :  0.010103619020576651 Loss D fake :  0.0103729393772952 Loss G :  0.010364536521848105 Epsilon spent :  6.629917628476269\n",
      "Epoch : 52 Loss D real :  0.010102826077115105 Loss D fake :  0.010314311376680305 Loss G :  0.010352362664707971 Epsilon spent :  6.684668134492338\n",
      "Epoch : 53 Loss D real :  0.01007695837038243 Loss D fake :  0.010315695405242836 Loss G :  0.010393008538454731 Epsilon spent :  6.739418640508408\n",
      "Epoch : 54 Loss D real :  0.010075609523463744 Loss D fake :  0.010318679365782889 Loss G :  0.010385653943365384 Epsilon spent :  6.794169146524476\n",
      "Epoch : 55 Loss D real :  0.010045877299495841 Loss D fake :  0.010330545932677989 Loss G :  0.010346555915754663 Epsilon spent :  6.848919652540546\n",
      "Epoch : 56 Loss D real :  0.01009475761401714 Loss D fake :  0.01031757935924299 Loss G :  0.01035140119686668 Epsilon spent :  6.903670158556615\n",
      "Epoch : 57 Loss D real :  0.010106112906907366 Loss D fake :  0.010319136737255345 Loss G :  0.010374075743192154 Epsilon spent :  6.958420664572683\n",
      "Epoch : 58 Loss D real :  0.01011117337573968 Loss D fake :  0.010314399962621741 Loss G :  0.01035272055723563 Epsilon spent :  7.013171170588754\n",
      "Epoch : 59 Loss D real :  0.010083563089230951 Loss D fake :  0.010342847442271812 Loss G :  0.010368985727586702 Epsilon spent :  7.067921676604822\n",
      "Epoch : 60 Loss D real :  0.01009297590591683 Loss D fake :  0.010296826027236024 Loss G :  0.010352508879888984 Epsilon spent :  7.122672182620891\n",
      "Epoch : 61 Loss D real :  0.0100897821488875 Loss D fake :  0.010351459900413572 Loss G :  0.010367509460090307 Epsilon spent :  7.177422688636961\n",
      "Epoch : 62 Loss D real :  0.01011456915978049 Loss D fake :  0.010309600804107873 Loss G :  0.010364286541075605 Epsilon spent :  7.232173194653029\n",
      "Epoch : 63 Loss D real :  0.010073297065951526 Loss D fake :  0.010306266400890825 Loss G :  0.010385946221852214 Epsilon spent :  7.2869237006690994\n",
      "Epoch : 64 Loss D real :  0.010140064584080033 Loss D fake :  0.0102955053618635 Loss G :  0.010360330913323394 Epsilon spent :  7.341674206685168\n",
      "Epoch : 65 Loss D real :  0.010081126686356974 Loss D fake :  0.010300049957900747 Loss G :  0.010359418967351458 Epsilon spent :  7.396424712701237\n",
      "Epoch : 66 Loss D real :  0.010091275625375219 Loss D fake :  0.010317074996731075 Loss G :  0.01032993764603235 Epsilon spent :  7.451175218717307\n",
      "Epoch : 67 Loss D real :  0.010102586836714392 Loss D fake :  0.01030946738686145 Loss G :  0.010409212186683624 Epsilon spent :  7.505925724733375\n",
      "Epoch : 68 Loss D real :  0.01007734866418989 Loss D fake :  0.010288626308064434 Loss G :  0.010354670857134984 Epsilon spent :  7.560676230749444\n",
      "Epoch : 69 Loss D real :  0.010084918265987104 Loss D fake :  0.01032990402068348 Loss G :  0.010348767538304644 Epsilon spent :  7.615426736765514\n",
      "Epoch : 70 Loss D real :  0.01009859796232262 Loss D fake :  0.0103034011258366 Loss G :  0.01034095170254721 Epsilon spent :  7.670177242781582\n",
      "Epoch : 71 Loss D real :  0.01008589088511539 Loss D fake :  0.010296242383307893 Loss G :  0.010347727496656809 Epsilon spent :  7.724927748797652\n",
      "Epoch : 72 Loss D real :  0.010137588361521451 Loss D fake :  0.010268649496640803 Loss G :  0.010364173924263614 Epsilon spent :  7.779678254813721\n",
      "Epoch : 73 Loss D real :  0.01009260450482927 Loss D fake :  0.010297093736920749 Loss G :  0.010375041377714115 Epsilon spent :  7.83442876082979\n",
      "Epoch : 74 Loss D real :  0.010111437502995035 Loss D fake :  0.010328949680702517 Loss G :  0.01034576096018017 Epsilon spent :  7.88917926684586\n",
      "Epoch : 75 Loss D real :  0.010068494841051443 Loss D fake :  0.010312754439021226 Loss G :  0.010344919670822747 Epsilon spent :  7.943929772861928\n",
      "Epoch : 76 Loss D real :  0.010118532348776436 Loss D fake :  0.010315777097913648 Loss G :  0.010354468882261839 Epsilon spent :  7.998680278877998\n",
      "Epoch : 77 Loss D real :  0.010089600423886128 Loss D fake :  0.010314086915534657 Loss G :  0.010330129568330992 Epsilon spent :  8.053430784894067\n",
      "AUC scores of downstream classifiers on test data : \n",
      "----------------------------------------\n",
      "LR: 0.2939953484741634\n",
      "----------------------------------------\n",
      "Random Forest: 0.5387715036451541\n",
      "----------------------------------------\n",
      "Neural Network: 0.20706299307640147\n",
      "----------------------------------------\n",
      "GaussianNB: 0.4640931819055621\n",
      "----------------------------------------\n",
      "GradientBoostingClassifier: 0.2909907762834354\n",
      "Saved synthetic data at :  /home/ec2-user/studies/GRAIMatter/data/Synthetic_generation/Synthetic/\n"
     ]
    }
   ],
   "source": [
    "# Firstly with no differential privacy. \n",
    "s0=syscom_synth(orig_path,synth_path,pdg_path,\n",
    "             'simple_logistic/simple_logistic_train.csv','simple_logistic/simple_logistic_test.csv',\n",
    "             'Y',synth_method,synth_extra,0,0)\n",
    "if show_output:\n",
    "    os.system(s0)\n",
    "else:\n",
    "    s0_out=os.popen(s0).read()\n",
    "s0_mv=\"mv \"+synth_path+\"synthetic_data.csv \"+synth_path+\"simple_logistic_0_\"+synth_method+\".csv\"\n",
    "os.system(s0_mv)\n",
    "\n",
    "# With differential privacy\n",
    "for dp in dp_levels:\n",
    "    print(\"Processing differential privacy level \"+str(dp))\n",
    "    sdp=syscom_synth(orig_path,synth_path,pdg_path,\n",
    "             'simple_logistic/simple_logistic_train.csv','simple_logistic/simple_logistic_test.csv',\n",
    "             'Y',synth_method,synth_extra,dp,0)\n",
    "    if show_output:\n",
    "        os.system(sdp)\n",
    "    else:\n",
    "        sdp_out=os.popen(sdp).read()\n",
    "    sdp_mv=\"mv \"+synth_path+\"synthetic_data.csv \"+synth_path+\\\n",
    "           \"simple_logistic_\"+str(dp)+\"_\"+synth_method+\".csv\"\n",
    "    os.system(sdp_mv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a8ca65-bb27-405e-8f52-bb0b5c69f41e",
   "metadata": {},
   "source": [
    "We now read synthetic-datasets back in. We fit (M-open) models to\n",
    " - the test set\n",
    " - a synthetic dataset with no DP guarantee\n",
    " - DP-guaranteed synthetic datasets\n",
    "and test them on the original test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1542042-0310-40ea-a5c5-16b91d6c1dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/ec2-user/studies/GRAIMatter/data/Synthetic_generation/Synthetic/simple_logistic_0_dp-wgan.csv\n",
      "Loading /home/ec2-user/studies/GRAIMatter/data/Synthetic_generation/Synthetic/simple_logistic_1_dp-wgan.csv\n",
      "Loading /home/ec2-user/studies/GRAIMatter/data/Synthetic_generation/Synthetic/simple_logistic_2_dp-wgan.csv\n",
      "Loading /home/ec2-user/studies/GRAIMatter/data/Synthetic_generation/Synthetic/simple_logistic_4_dp-wgan.csv\n",
      "Loading /home/ec2-user/studies/GRAIMatter/data/Synthetic_generation/Synthetic/simple_logistic_8_dp-wgan.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------  ---------  --------  ----------  --------\n",
      "True           5         10        -10         -5\n",
      "Orig.          4.3127     8.8989    -8.77168   -4.3019\n",
      "Synth, no DP   3.19753   -5.7831     0.18042   14.7011\n",
      "DP 1          -2.07511   -3.0026    -0.379445   7.17053\n",
      "DP 2           1.12212    6.83135   19.9633     3.88626\n",
      "DP 4          -5.46788   -5.95798    8.37287   20.9923\n",
      "DP 8           0.997225  -3.25346   34.6269    19.8237\n",
      "------------  ---------  --------  ----------  --------\n"
     ]
    }
   ],
   "source": [
    "## Model fitted to original training data\n",
    "model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "model.fit(cov_train,y_train)\n",
    "ypred_test_orig=model.predict_proba(cov_test)[:,1]\n",
    "beta_orig=model.coef_\n",
    "\n",
    "## Model fitted to synthetic dataset with no DP guarantee\n",
    "# Read in\n",
    "s0_path=synth_path+\"simple_logistic_0_\"+synth_method+\".csv\"\n",
    "print(\"Loading \"+s0_path)\n",
    "synth0 = np.loadtxt(s0_path, delimiter=\",\",skiprows=1)[:,1:]\n",
    "# Fit model\n",
    "model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "model.fit(synth0[:,0:p],synth0[:,p:(p+1)])\n",
    "ypred_test_0=model.predict_proba(cov_test)[:,1]\n",
    "beta_0=model.coef_\n",
    "\n",
    "# Models fitted to DP datasets\n",
    "ypred_test_dp=np.zeros([nx,len(dp_levels)])\n",
    "beta_dp=np.zeros([p,len(dp_levels)])\n",
    "for i in list(range(0,len(dp_levels))):\n",
    "    dp=dp_levels[i]\n",
    "    sdp=synth_path+\"simple_logistic_\"+str(dp)+\"_\"+synth_method+\".csv\"\n",
    "    print(\"Loading \"+sdp)\n",
    "    synthd = np.loadtxt(sdp, delimiter=\",\",skiprows=1)[:,1:]\n",
    "    # Fit model\n",
    "    model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    model.fit(synthd[:,0:p],synthd[:,p:(p+1)])\n",
    "    ypred_test_d=model.predict_proba(cov_test)[:,1]\n",
    "    ypred_test_dp[:,i]=ypred_test_d\n",
    "    beta_dp[:,i]=model.coef_\n",
    "\n",
    "## Plot ROC curves\n",
    "\n",
    "# Original data\n",
    "ss_orig=roc_xy(ypred_test_orig,y_test)\n",
    "plt.plot(1-ss_orig[:,1],ss_orig[:,0],label=\"Orig\",color=\"black\")\n",
    "\n",
    "# No DP\n",
    "ss_0=roc_xy(ypred_test_0,y_test)\n",
    "plt.plot(1-ss_0[:,1],ss_0[:,0],label=\"No DP\",color=\"red\")\n",
    "\n",
    "# DP levels\n",
    "for i in list(range(0,len(dp_levels))):\n",
    "    ss_dp=roc_xy(ypred_test_dp[:,i],y_test)\n",
    "    plt.plot(1-ss_dp[:,1],ss_dp[:,0],\n",
    "             label=\"DP\"+str(dp_levels[i]),\n",
    "             color=str((i+1)/(len(dp_levels)+1)))\n",
    "\n",
    "# X-Y line\n",
    "plt.plot([0,1],[0,1],linestyle=\"--\",linewidth=1,color=\"black\")\n",
    "\n",
    "# Draw plot\n",
    "plt.title('ROCs for DP')\n",
    "plt.xlabel('1-spec')\n",
    "plt.ylabel('Sens')\n",
    "plt.legend()\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(output_path+'Figures/DP_ROC_'+synth_method+\"_\"+str(nx)+'.pdf', bbox_inches='tight')\n",
    "\n",
    "# Show figure\n",
    "plt.show()\n",
    "\n",
    "# Print betas\n",
    "btab=np.concatenate(\n",
    "    (np.reshape(np.array(beta),(1,p)),\n",
    "     beta_orig,\n",
    "     beta_0,\n",
    "     beta_dp))\n",
    "rindex=[\"True\",\"Orig.\",\"Synth, no DP\"] + [\"DP \"+str(d) for d in dp_levels]\n",
    "print(tabulate(btab,showindex=rindex))\n",
    "\n",
    "# Write to table\n",
    "with open(output_path+'Tables/DP_beta_'+synth_method+'_'+str(nx)+'.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(rindex)\n",
    "    writer.writerows(np.transpose(btab))\n",
    "    f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baed00d-c795-4084-8d83-10cce57687c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
