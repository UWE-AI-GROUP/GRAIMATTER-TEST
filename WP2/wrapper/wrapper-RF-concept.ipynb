{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b8ac33-d00b-4d38-bc76-a649325e18a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file wrapper-concept.ipynb\n",
    "# author Jim Smith Jan 2022\n",
    "# note book to explore and illustrate the basic concept of a wrapper class\n",
    "\n",
    "## Edited Andy McCarthy Feb 2022 to adapt to illustrate the use of safe_random_forest class\n",
    "# params protected are boostrap==True and min_samples_leaf = 5\n",
    "\n",
    "# edit jim Smith Feb 18 to use multple inheritance vesion of safemodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d92b96-a6bc-4b1b-9040-f81c095e8770",
   "metadata": {},
   "source": [
    "## Some basic examples to explore what the wrapper class could look like and be implemented\n",
    "\n",
    "### Lets start by making some data with one disclosive case\n",
    "- We'll do this by adding an example to the iris data and give it a new class to make things really obvious.\n",
    "- The same risks exist for more complex data sets but _everyone knows iris_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e9809e-f778-48de-9857-a6a481d96cd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "\n",
    "# print the max and min values in each feature to help hand-craft the disclosive point\n",
    "for feature in range(4):\n",
    "    print(f\"feature {feature} min {np.min(X[:,feature])}, min {np.max(X[:,feature])}\")\n",
    "\n",
    "# now add a single disclosve point with features [7,2,4.5,1] and label 3\n",
    "X = np.vstack([X, (7, 2.0, 4.5, 1)])\n",
    "y = np.append(y, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5effc9f-f2b3-4e8c-b2c3-87633c7a76fb",
   "metadata": {},
   "source": [
    "### and import some basic libraries to show our point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ba8d9-c78e-4259-bd49-802481b70ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d657d29-6edb-4e50-813e-654b104c7f75",
   "metadata": {},
   "source": [
    "## Here's the raw version\n",
    "-  note I am setting random_state=1 to make it deterministic, just so you get the same results as me\n",
    " - the general point is not that someone always will, but that they could\n",
    " - in practice I ran 10 times not setting random state and got the same tree 4/5 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e85c9-5516-43f7-bb96-ddb48dc08d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example code with no safety\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rawRF = RandomForestClassifier(max_depth=5, random_state=1)\n",
    "rawRF.fit(X, y)\n",
    "\n",
    "print(f\"Training set accuracy in this naive case is {rawRF.score(X,y)}\")\n",
    "print(\"Fairly randomly selecting two of the trees in the forest to display\")\n",
    "\n",
    "estimator = rawRF.estimators_[5]\n",
    "estimator1 = rawRF.estimators_[50]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 10))\n",
    "_ = plot_tree(estimator, filled=True, ax=ax[0], fontsize=11)\n",
    "_ = plot_tree(estimator1, filled=True, ax=ax[1], fontsize=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd44240-2ed4-4e94-9633-94057220d686",
   "metadata": {},
   "source": [
    "### As we can see we have several disclosive nodes, one of which is our added point (in purple)\n",
    "\n",
    "- A single tree that has a leaf corresponding to our new point may not give tight bounds on every feature value\n",
    "- But every additional tree restricts those bounds - especially if each uses different combinations of features\n",
    "- so the risk of complete disclosure of that point increases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcf587c-fd29-4801-ba9b-51a342ac8aed",
   "metadata": {},
   "source": [
    "### Diligent user realises problem, and changes their code to see if enforcing at least n samples in each leaf and/or  bootstrapping helps\n",
    "- We'll use n=5 \n",
    "- note that we need to combination of both of these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ccce71",
   "metadata": {},
   "source": [
    "## Scenario. 1: Boostrap=True and min_samples_leaf = 1:  low MIA risk (per Simon) but singleton disclosure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc6e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "manualRF1 = RandomForestClassifier(bootstrap=True, min_samples_leaf=1, random_state=1)\n",
    "manualRF1.fit(X, y)\n",
    "print(f\"Training set accuracy in scenario 1 is {manualRF1.score(X,y)}\")\n",
    "fig, ax = plt.subplots(10, 10, figsize=(15, 15))\n",
    "for row in range(10):\n",
    "    for column in range(10):\n",
    "        whichTree = 10 * row + column\n",
    "        treeRowCol = manualRF1.estimators_[whichTree]\n",
    "        _ = plot_tree(treeRowCol, filled=True, ax=ax[row][column], fontsize=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3292db",
   "metadata": {},
   "source": [
    "## Scenario 2: Boostrap=True and min_samples_leaf = 5: no singleton disclosure  high MIA risk  (per Simon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e916e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "manualRF2 = RandomForestClassifier(bootstrap=True, min_samples_leaf=5, random_state=1)\n",
    "manualRF2.fit(X, y)\n",
    "print(f\"Training set accuracy in scenario 2 is {manualRF2.score(X,y)}\")\n",
    "fig, ax = plt.subplots(10, 10, figsize=(15, 15))\n",
    "for row in range(10):\n",
    "    for column in range(10):\n",
    "        whichTree = 10 * row + column\n",
    "        treeRowCol = manualRF2.estimators_[whichTree]\n",
    "        _ = plot_tree(treeRowCol, filled=True, ax=ax[row][column], fontsize=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3524cc",
   "metadata": {},
   "source": [
    "## Scenario 3: Boostrap=True and min_samples_leaf = 5: no singleton disclosure, low MIA risk (per Simon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09828536",
   "metadata": {},
   "outputs": [],
   "source": [
    "manualRF3 = RandomForestClassifier(bootstrap=True, min_samples_leaf=5, random_state=1)\n",
    "manualRF3.fit(X, y)\n",
    "print(f\"Training set accuracy in scenario 3 is {manualRF3.score(X,y)}\")\n",
    "fig, ax = plt.subplots(10, 10, figsize=(15, 15))\n",
    "for row in range(10):\n",
    "    for column in range(10):\n",
    "        whichTree = 10 * row + column\n",
    "        treeRowCol = manualRF3.estimators_[whichTree]\n",
    "        _ = plot_tree(treeRowCol, filled=True, ax=ax[row][column], fontsize=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968acece-746d-4b53-a20d-ef100e1b59a8",
   "metadata": {},
   "source": [
    "### This shows we need both parameters to. be set for the output to be non-disclosive\n",
    "- Simon has shown elsewhere Bootstrap =False leads to high MIA risk\n",
    "- middle plot shows even bootstrap = True can lead to multiple trees with singleton leaves which pose individual disclosure risk\n",
    "- You can easily see we don't get a node for the new class 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1d51e4-a2ad-41e9-bd59-389741c1d996",
   "metadata": {},
   "source": [
    "## So lets define a new class SafeDecisionTree \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c88914-790f-417c-89b7-6641f2ca6539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, SafeModel\n",
    "\n",
    "importlib.reload(SafeModel)\n",
    "\n",
    "\n",
    "from SafeModel import SafeModel, SafeRandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8993ca95-4e71-48e4-8b11-783fcffcdec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "noNameModel = SafeModel()\n",
    "\n",
    "try:\n",
    "    print(noNameModel.__str__())\n",
    "except:\n",
    "    print(\"super class has no attributes to print\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504c3c64-adcf-4796-b4ef-c574a6cfe1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "safeRFModel = SafeRandomForest()  # (criterion=\"entropy\")\n",
    "# print(safeRFModel.__str__())\n",
    "safeRFModel.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92b751a-5d23-4019-bc54-3986c072c9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "safeRFModel.fit(X, y)\n",
    "\n",
    "print(f\"Training set accuracy in this safe case is {safeRFModel.score(X,y)}\")\n",
    "print(\n",
    "    \"Not the same as last time because I have not specified the random state and here are  the trees again\"\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(10, 10, figsize=(15, 15))\n",
    "for row in range(10):\n",
    "    for column in range(10):\n",
    "        whichTree = 10 * row + column\n",
    "        treeRowCol = safeRFModel.estimators_[whichTree]\n",
    "        _ = plot_tree(treeRowCol, filled=True, ax=ax[row][column], fontsize=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894919fa-17d4-41cc-b065-690e10cdc192",
   "metadata": {},
   "source": [
    "## Now demonstrate the save and reporting functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fec67c3-4b39-4d90-aa83-45ca576742ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "safeRFModel.save(name=\"testSaveRF.pkl\")\n",
    "safeRFModel.preliminary_check()\n",
    "safeRFModel.request_release(\"testSaveRF.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27211998-c809-4c20-96c7-49909983f1af",
   "metadata": {},
   "source": [
    "## Now lets try to attack this approach\n",
    "### starting with listing the params then trying to set the params manually after init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f393ab2-9237-43ed-8921-36ffd0044e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(safeRFModel.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c060b2c1-9866-4eb4-93fd-083db423f393",
   "metadata": {},
   "outputs": [],
   "source": [
    "safeRFModel.min_samples_leaf = 1\n",
    "\n",
    "safeRFModel.fit(X, y)\n",
    "\n",
    "print(f\"Training set accuracy in this naive case is {safeRFModel.score(X,y)}\")\n",
    "print(\"you can see there are now unsafe trees again\")\n",
    "\n",
    "fig, ax = plt.subplots(10, 10, figsize=(15, 15))\n",
    "for row in range(10):\n",
    "    for column in range(10):\n",
    "        whichTree = 10 * row + column\n",
    "        treeRowCol = safeRFModel.estimators_[whichTree]\n",
    "        _ = plot_tree(treeRowCol, filled=True, ax=ax[row][column], fontsize=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf0bb1a-1a5e-4702-9c4d-cdafa2bc1b8a",
   "metadata": {},
   "source": [
    "### This has let the user reset the params so that the model is now disclosive once again.\n",
    "\n",
    "## Question: what do we do here:\n",
    "1. Find a way of obfuscating the params so that they cannot be changed from outside the wrapper class\n",
    "  - hard, not very python esque\n",
    "  - also what if the use wants to increase min_samples_leaf which would make the model less disclosive than the default values?\n",
    "  - **we've discarded this approach as impractical**\n",
    "2. Put code into various method within the main class that checks the param values and says if they have been changed.\n",
    " - constraints are  stored the \"safe\" param values in a read-only file  \n",
    "   and reads that into a dict in the init() and preliminary_check() and request_release() methods. \n",
    "    - The dict key is name of parameter name, value is a tuple of [operator, value]  \n",
    "      where operator is one of [\"min\" |\"equals\" | \"max\"] and value is applied to operator\n",
    "    - the dict is read afresh in __init__() and in make_report() to prevent users amending values \n",
    " - this would have the benefit of allowing users to increase the min_samples_leaf but report when it was taken below our threshold\n",
    " \n",
    " - issue is how to deal with situations where the safety is built from a non-linear interaction between param values\n",
    "   - that is a problem to deal with in the second stage of the project once we have proved the concept\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b352bb2-3608-433e-b586-b235344ec58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit using recommended params\n",
    "print(\"***Test 1: researcher doesn't change recommended params\")\n",
    "safeRFModel2 = SafeRandomForest()\n",
    "safeRFModel2.fit(X, y)\n",
    "safeRFModel2.save(name=\"safe2.pkl\")\n",
    "safeRFModel2.preliminary_check()\n",
    "safeRFModel2.request_release(filename=\"safe2.pkl\")\n",
    "\n",
    "\n",
    "# change model params to recommended values\n",
    "print(\"\\n***Test 2: researcher changes params safely\")\n",
    "safeRFModel3 = SafeRandomForest()\n",
    "safeRFModel3.min_samples_leaf = 6\n",
    "safeRFModel3.fit(X, y)\n",
    "safeRFModel3.save(name=\"safe3.pkl\")\n",
    "safeRFModel3.preliminary_check()\n",
    "safeRFModel3.request_release(filename=\"safe3.pkl\")\n",
    "\n",
    "\n",
    "# change one model params in an unsafe way\n",
    "print(\"\\n***Test 3: researcher changes string params unsafely\")\n",
    "safeRFModel4 = SafeRandomForest()\n",
    "safeRFModel4.bootstrap = False\n",
    "safeRFModel4.fit(X, y)\n",
    "safeRFModel4.save(name=\"unsafe1.pkl\")\n",
    "safeRFModel4.preliminary_check()\n",
    "safeRFModel4.request_release(filename=\"unsafe1.pkl\")\n",
    "\n",
    "\n",
    "# change another model params in an  unsafe way\n",
    "print(\"\\n***Test 4: researcher changes numeric params unsafely\")\n",
    "safeRFModel5 = SafeRandomForest()\n",
    "safeRFModel5.bootstrap = True\n",
    "safeRFModel5.min_samples_leaf = 2\n",
    "safeRFModel5.save(name=\"unsafe2.pkl\")\n",
    "safeRFModel5.preliminary_check()\n",
    "safeRFModel5.request_release(filename=\"unsafe2.pkl\")\n",
    "\n",
    "# change another model params in an  unsafe way\n",
    "print(\"\\n***Test 5: researcher changes string and numeric params unsafely\")\n",
    "safeRFModel6 = SafeRandomForest()\n",
    "safeRFModel6.bootstrap = False\n",
    "safeRFModel6.min_samples_leaf = 2\n",
    "safeRFModel6.save(name=\"unsafe3.pkl\")\n",
    "safeRFModel6.preliminary_check()\n",
    "safeRFModel6.request_release(filename=\"unsafe3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c59ee3b-52fb-4aa8-a481-6ca879a14466",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"contents of checkfile are\"; cat *_check*ile.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
