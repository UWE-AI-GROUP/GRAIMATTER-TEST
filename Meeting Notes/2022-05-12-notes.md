# Meeting agenda / notes, 2022-05-12

## Apologies

## Agenda

1. WP1 update
    1. Need to re-run experiments with new metric. Waiting simon to check configs...sorry!
1. WP2 update
	1. Safe Keras -- DP Optimizers apply constraints
	1. Automating attribute inference for categorical and continuous, what metrics to report.
1. Evidence to backup recommendations -- what needs to be done? and who is going to do it
    1. Scenario comparison for recommending that assessment based on "Worst Case" is sufficient.
    1. Extraction of dangerous parameter values.
    1. ...?
1. Open questions
    1. White box -- we have not done much on this. What do we need to do? For NNs, this covers things like transfer learning. For other ML, it covers things like ensembles -- an ensemble that looks safe doesn't mean that the base learners are safe.
1. SVM case study with Susan Kreuger / PICTURES -- do we want to do this, and if so who will lead? (IMO it would be very useful to expierience actually trying what we're recommending. Perhaps first step would be setting up a meeting with Susan to scope the possibilities?)
1. Storyboarding for video for 25th May?
1. Working on text in main document -- division of labour
    1. Although our experiments can provide indications of safety, all models need to be checked themselves before disclosure
1. AOCB
1. Next chair

## Notes / Actions


1. Safe keras _almost_ done.
1. Attribute inference -- WP2 working on continuous attribute inference.
1. Are there random forest / boosting frameworks that use DP for base learners.
1. Alba running experiments. results are imminent
1. AUC appears a good metric; but we shouldn't rely on one metric. Threshold each metric, metrics > threshold are risky.
1. A disagreement matrix could be useful to see which metrics agree. 
